

\section{Marco Histórico}

\subsection{Historia y Reconocimiento del Lenguaje de Señas}

Cuando se hace un recuento histórico, se puede evidenciar que antes del siglo XVII, hay pocos registros escritos sobre el lenguaje de señas o la educación de personas sordas. Es por esto que es difícil hacer un recuento histórico de fechas que daten antes de esto, sin embargo, es importante anotar que las señas como una forma de comunicación que surge primero que la hablada en la historia de la humanidad. Siguiendo con la documentación histórica del lenguaje de señas, usualmente se reconocen figuras determinadas que demostraron el potencial intelectual de las personas sordas. Como por ejemplo, en Francia, una de las figuras más antiguas e importantes es Etienne de Fay (1669 - 1750). El cual fue sordo de nacimiento, además de ser educado en la abadía de Amiens, donde no solo aprendió a leer y escribir, sino que también fue capas de convertirse en un muy buen arquitecto, escultor y maestro para otros niños sordos\autocite[p.~13-15]{Fischer1993}. De Fay era capas de comunicarse con buenas habilidades a través del lenguaje de señas y también de educar a sus estudiantes utilizando tanto las señas como la escritura, demostrando que la educación podía llevar a la autonomía y la responsabilidad, es considerado el primer profesor para personas con discapacidad auditiva\autocite[p.~18]{Fischer1993}. Además, se considera que su vida representa una gran diferencia para la historia de los sordos en Francia, incluso siendo anterior a otra de las figuras más conocidas en esta parte de la historia, siendo L'Epée\autocite[p.~14]{Fischer1993}. El cual planteaba métodos diferentes de enseñanza en estas comunidades en particular. Por otro lado, la comunidad sorda siempre ha sufrido de ser marginada en varios aspectos desde periodos mucho más antiguos de lo que datan los registros y esta época no es la excepción, la mayoría de las personas sordas vivían en el aislamiento donde casi siempre eran confundidas con personas sin capacidad intelectual, y su acceso a la educación era prácticamente inexistente, a menos que pertenecieran a familias con muchos recursos que pudieran permitirse buenos tutores, marcando la separación entre la elite y las masas\autocite[p.~26]{Fischer1993}.\vspace{0.5cm}\par

Luego se realiza un salto en la historia a principios del siglo XIX, donde se puede evidenciar que el lenguaje de señas americano (ASL) está intrínsecamente ligado a la herencia francesa que se revisó anteriormente. Porque en 1817, gracias a la colaboración del reverendo estadounidense Thomas Hopkins Gallaudet y de Laurent Clerc, un muy buen profesor sordo del instituto de París, se pudo fundar el Asilo Americano para la Educación de Sordomudos (ahora conocida como la Escuela Americana para Sordos o ASD) en Hartford, Connecticut. El profesor Clerc no solo fue cofundador, sino que también el principal profesor, importando el Lenguaje de Señas Francés (LSF) al continente americano\autocite[p.~X]{Shaw2015}.\vspace{0.5cm}\par

El hecho de traer este lenguaje a un nuevo lugar provoco un cambio cultural en la ASD, donde el LSF de Clerc se logró mezclar con diversas formas de comunicación que ya utilizaban los estudiantes allí, quienes provenían de diferentes partes del país. Así mismo, entre estas formas de comunicación se encontraba el lenguaje de señas que ya existía en la isla de Martha's Vineyard. En este lugar, el lenguaje de señas se volvió una necesidad por una alta incidencia de sordera hereditaria que origino un lenguaje de señas utilizado tanto por personas sordas como oyentes. La combinación de estas diferentes corrientes, con sus bases predominantes en el LSF, dio origen a lo que hoy se conoce como ASL. Desde Hartford, el modelo educativo y el nuevo lenguaje de señas se expandieron rápidamente por todo Estados Unidos, donde los graduados de la ASD fundaban nuevas escuelas residenciales, asegurando de esta manera una notable uniformidad del ASL en las primeras generaciones de los hablantes\autocite[p.~X-XI]{Shaw2015}.\vspace{0.5cm}\par

Posteriormente, hubo un problema dentro de la comunidad hablante de señas debido al congreso de milán y la resistencia americana. Lo que sucedió, consistió en que Hacia finales del siglo XIX, la educación de la gente sorda se vio envuelta en un complicado debate filosófico que se originó entre los defensores del método manual, es decir los que usaban las señas, y los del método oral, que peleaban por enseñar a los sordos a hablar y leer los labios. Este problema alcanzó su punto más alto en el Segundo Congreso Internacional sobre la Educación de las personas sordas, el cual tuvo su origen en Milán en 1880. De esta manera, en el congreso, la mayoría de educadores, que cabe aclarar no poseían ninguna discapacidad, votó a favor de la prohibición del lenguaje de señas en la educación, lo que ocasiono la prevalencia del método oral sobre toda Europa\autocite[p.~XI]{Shaw2015}.\vspace{0.5cm}\par

Este suceso ocurrido en el edicto de Milán tuvo consecuencias devastadoras en Europa, llevando a la supresión casi en su totalidad del lenguaje de señas en las escuelas, además de la marginación de los profesores sordos y los estudiantes que usaran las señas, donde los vigilaban constantemente para evitar que lo hicieran, esto fue muy malo, pues era la manera en la cual podían enseñar y comunicarse. En ese momento, en Francia, la comunidad sorda tuvo que ver con desesperación cómo su lengua era borrada de las aulas durante décadas\autocite[p.~XI]{Shaw2015}. Sin embargo, en Estados Unidos la reacción fue bastante diferente. Aunque el oralismo ganó mucho terreno, la comunidad sorda de América, gracias a que estaba fortalecida por varias escuelas que enseñaban las señas por varios años, además de tener muchos exalumnos educados y organizaciones como la Asociación Nacional de Sordos (NAD) que se dedicaban a las señas, pudo crear una muy buena resistencia. Durante esta época de resistencia, en los próximos años 1904 al 1910, la NAD genero varias películas que mostraban la indignación de las personas ante los "falsos profetas" que impartían el oralismo, unificando a la comunidad sorda de América.\autocite[p.~XIII]{Shaw2015}. Por otro lado, factores como la distancia cultural a Europa, además de la autonomía que tenían las escuelas estatales, sin olvidar el apoyo de grupos religiosos que veían en las señas un medio eficaz para la evangelización permitieron que el ASL sobreviviera, aunque algunas veces de forma clandestina dentro de las escuelas que oficialmente adoptaban el oralismo. Pero prevaleciendo el hecho que en America aumento el uso de las señas comparando con Francia, esto se puede ver también en la manera en la que cambiaron los lenguajes a través de la historia\autocite[p.~XIV]{Shaw2015}.\vspace{0.5cm}\par

A pesar de este problema, a principios del siglo XX, en plena pelea que estaba en contra del oralismo, la comunidad sorda estadounidense empezó medidas bastante buenas para preservar su lengua. Como se mencionó antes, la NAD, bajo el liderazgo de su presidente George Veditz, emprendió un proyecto pionero, el cual consistía en grabar una serie de películas que luego se popularizarían entre los años 1910 y 1920 para documentar y preservar "la belleza y la gracia del lenguaje de señas" para las generaciones futuras\autocite[p.~3]{Supalla2015}. Estas películas no solo son un testimonio de la resistencia de la comunidad, sino también una gran oportunidad para admirar y apreciar la evolución del ASL, esto porque se dice porque en estas aparecen "maestros de las señas" de diferentes generaciones, mostrando las variaciones diacrónicas y sincrónicas del lenguaje a lo largo de los años. Por ejemplo, se puede observar cómo señas que originalmente eran compuestos de dos movimientos, como la seña de PADRE (una combinación de "hombre" y "engendrar"), se fueron reduciendo y simplificando con el tiempo hasta llegar finalmente a la forma moderna de un solo toque en la frente.\autocite[p.~4-5]{Supalla2015}\vspace{0.5cm}\par

Es en este mismo momento en que se logran publicar los primeros diccionarios de ASL, como los de J. Schuyler Long (1910) y Daniel D. Higgins (1923), con el objetivo de llegar a estandarizar y preservar la "pureza original" de la lengua frente a la creciente amenaza del oralismo. Este periodo, aunque difícil y conocido como la época oscura, demostró la resiliencia de la comunidad sorda y su profundo arraigo con su identidad lingüística y cultural.\autocite[p.~XIV]{Shaw2015}.\vspace{0.5cm}\par

Así mismo, esta resiliencia dio frutos porque pesar de la opresión, la comunidad sorda logro resistir. Es importante señalar, que el punto de inflexión más significativo del siglo XX llegó desde el punto de vista académico. Esto gracias a William C. Stokoe, el cual fue un lingüista estadounidense que en 1960, fue el primero en demostrar científicamente que el ASL no era algo simple y superficial o un código gestual, sino más bien una lengua verdadera y compleja, con su propia fonología, morfología y sintaxis\autocite[p.~XIV]{Shaw2015}. Con este análisis lingüístico estableció la riqueza del ASL e impulso en diferentes círculos académicos su reintroducción en la educación y sentó las bases para su reconocimiento académico.\vspace{0.5cm}\par

Gracias al trabajo de Stokoe, junto con el impulso que tuvo el movimiento por los derechos civiles en Estados Unidos, liderado por Martin Luther King, genero un cambio de percepción, donde Las personas sordas comenzaron a verse a sí mismas como una minoría lingüística y cultural haciendo que su lucha por los derechos se intensificara\autocite[p.~517]{Fischer1993}. Por otro lado, en Francia, este surgimiento de espíritu de lucha se conoció como el Réveil sourd (El despertar sordo), el cual consistió en un movimiento para reafirmar el Lenguaje de Señas Francés (LSF) después de un siglo de represión desde el Congreso de Milán\autocite[p.~XII]{Shaw2015}.\vspace{0.5cm}\par

Sin embargo, también estaban ocurriendo otros movimientos a nivel internacional, el movimiento por el reconocimiento de los lenguajes de señas ganó impulso en otros lados del mundo. Por ejemplo, en Alemania, un logro bastante grande fue en el Congreso de Hamburgo de 1985, donde se declaró por primera vez que el Lenguaje de Señas Alemán era un sistema lingüístico independiente y completo. Además, este evento fue un antes y después en la historia de la comunidad sorda alemana y significo después en la fundación del Centro de Lenguaje de Señas Alemán en Hamburgo en 1987. Por otro lado, también significo que la lucha política se intensificara, dando como resultado a los líderes sordos comenzando a exigir una participación activa en la educación de los niños sordos\autocite[p.~188-189]{Fischer1993}.\vspace{0.5cm}\par

Por último, la década de 1980 se conoció por culminar con dos eventos muy importantes. El primero de ellos, En 1988, fue que el Parlamento Europeo adoptó una resolución comunicando a los países miembros a reconocer legalmente sus respectivos lenguajes de señas nacionales\autocite[p.~204]{Fischer1993}. Y la segunda fue la victoria en la universidad Gallaudet en Rusia, donde los estudiantes protestaron con éxito para que se nombrara al primer presidente sordo de la universidad, este hecho se supo mucho después, luego de 75 años, por culpa de la dificultad que tenía ese país en dicha época, donde la información era bastante limitada y lo que le pasaba a la comunidad sorda de Rusia estaba totalmente aislado\autocite[p.~195]{Fischer1993}. De estos hechos a la actualidad, la lucha por los derechos de las personas sordas sigue en pie, donde a través de la tecnología se ha tratado de dar una solución, sin embargo, aún no se ha encontrado una respuesta definitiva como se puede apreciar en el siguiente apartado con la revisión histórica de la detección de señas.\vspace{0.5cm}\par

\subsection{Evolución de la Tecnología de Reconocimiento del Lenguaje de Señas}

Cuando se  analiza la evolución de la tecnología se pueden reconocer diferentes etapas,  que se diferencian por los avances en inteligencia artificial y visión por computador. Cuando se habla de la primera década de los últimos 20 años, se ve que en el campo del reconocimiento del lenguaje de señas, y también el del Lenguaje de Señas Chino (CSLR), se centró en su mayoría en aplicaciones y sistemas basados en sensores. Además, durante este período de experimentación, los investigadores tenían de métodos que requerían contacto físico o dispositivos que eran muy especializados. Donde la recolección de datos se realizaba a través de guantes de datos (data gloves) y sensores de movimiento como Kinect y Leap Motion\autocite[p.~3]{Jiang2024}.\vspace{0.5cm}\par

Siguiendo este orden de ideas, las tecnologías de clasificación que se veían de manera más común en esta etapa eran los Modelos Ocultos de Márkov (HMM), las Máquinas de Vectores de Soporte (SVM) y el Almacenamiento de Contraste Dinámico (DTW)\autocite[p.~3]{Jiang2024}. Donde estos métodos clásicos se aplicaban principalmente al reconocimiento de señas aisladas o al deletreo manual (dactilología), la particularidad de estos gestos es que se realizan de uno en uno en un entorno controlado, lo cual representaría un futuro problema donde hasta los métodos actuales se esfuerzan por poder reconocer los gestos en espacios continuos\autocite[p.~23]{Hashi2024}. No obstante, esta primera generación de sistemas presentaba limitaciones mu grandes, las cuales eran, el costo del reconocimiento, donde este era relativamente alto y la precisión era comparativamente baja. Sin olvidar que, la dependencia de tener sensores hacía que los sistemas fueran casi siempre invasivos y poco prácticos para el uso del día a día\autocite[p.~3]{Jiang2024}.\vspace{0.5cm}\par

Por otro lado, se provocó un cambio en las dinámicas, permitiendo que surgiera en mayor medida las técnicas por visión por computador y de aprendizaje profundo. Este cambio se originó en la última década, impulsado por el rápido desarrollo de la visión por computadora y las tecnologías de inteligencia artificial\autocite[p.~2]{Jiang2024}. Este período tiene la peculiaridad de haber marcado un cambio de paradigma desde los métodos basados en sensores hacia técnicas basadas en la visión, que utilizan cámaras para capturar el movimiento de las manos y el cuerpo sin necesidad de contacto para medir las distancias de los dedos con respecto a la posición de la mano\autocite[p.~3]{Jiang2024}.\vspace{0.5cm}\par

Es en esta  transición que ocurre algo importante, que sería la publicación del trabajo de Su et al. en 2016, quienes propusieron un método no visual para el reconocimiento del lenguaje de señas basado en acelerometría (ACC) y electromiografía de superficie (sEMG), utilizando un algoritmo de Random Forest que alcanzó una notable precisión del 98.25\% en la clasificación de 121 palabras del CSL\autocite[p.~12]{Jiang2024}. Casi al mismo tiempo de este hecho, el potencial del aprendizaje profundo se hizo mucho más evidente, gracias a que en 2017, Yang et al. utilizaron una Red Neuronal Convolucional (CNN) que junto a una segmentación de manos para verificar 40 palabras del vocabulario de señas, pudo lograr una tasa de reconocimiento del 99.00\%\autocite[p.~13]{Jiang2024}.\vspace{0.5cm}\par

Consecuentemente con lo anterior, estos avances demostraron que los enfoques basados en visión y aprendizaje profundo no solo podían igualar, sino que también superar la precisión de los anteriores sistemas basados en sensores, dándole paso a una nueva era de investigación. La introducción de arquitecturas innovadoras como el modelo Transformer por Vaswani et al. en 2017 y BERT por Devlin et al. en 2018 ayudaron a sentar las bases para modelos de lenguaje y reconocimiento mucho más potentes y contextuales.\autocite[p.~19]{Jiang2024}.\vspace{0.5cm}\par

Ahora bien, con las bases sentadas, se puede ver que desde 2018 hasta el presente, la investigación en SLR (reconocimiento de lenguaje de señas) ha entrado en una fase que se puede considerar de perfeccionamiento, con un enfoque particular en la aplicación de técnicas de aprendizaje profundo para abordar los aspectos más complejos del lenguaje de señas\autocite[p.~3]{Hashi2024}. Cuando se menciona el uso de la tecnología CNN, se evidencia que se ha generalizado desde 2019, y además ha sido complementado por arquitecturas más avanzadas como las 3D-CNN, Redes Neuronales Recurrentes (entre otras de sus variantes como LSTM), y los modelos Transformer, lo cuales son más adecuados para el reconocimiento de lenguaje de señas continuo debido a su capacidad para procesar la dinámica temporal y la información contextual\autocite[p.~28]{Jiang2024}.\vspace{0.5cm}\par

Así mismo, los enfoques de investigación actuales se centran en superar determinados desafíos clave. Como por ejemplo. uno de ellos es lograr un reconocimiento de lenguaje de señas que pueda ser independiente del intérprete, donde los marcos de aprendizaje profundo pudieron mostrar resultados buenos\autocite[p.~3]{Hashi2024}. De igual manera, se está reconociendo cada vez más la importancia de los componentes no manuales del lenguaje de señas, es decir, las expresiones faciales y la postura corporal, además de trabajar en la integración de estos elementos en las tecnologías para mejorar la precisión y robustez de los sistemas\autocite[p.~3]{Hashi2024}. Gracias a esto, se pudo potenciar a 2021 las investigaciones que destacan la integración de redes neuronales y de sensores equipables, como por ejemplo el uso de guantes de datos para el reconocimiento en tiempo real de movimientos dinámicos de los dedos\autocite[p.~11]{Hashi2024}.\vspace{0.5cm}\par

No obstante, a pesar de los avances que se han hecho hasta el día de hoy, todavía permanecen obstáculos significativos. Como por ejemplo, siendo este de los más importantes, la limitación de las bases de datos existentes, que casi siempre son pequeñas y carecen de diversidad, conteniendo solo alfabetos, números o un conjunto reducido de palabras\autocite[p.~1]{Hashi2024}. Gracias a la falta de datasets a gran escala y que sean diversos, especialmente enfocados para el lenguaje de señas continuo, es decir, en formato de videos o secuencias, dificulta el desarrollo de sistemas que puedan ser verdaderamente prácticos y, más aún, robustos\autocite[p.~23]{Hashi2024}. De igual manera, otros desafíos incluyen la necesidad de desarrollar mejores métodos híbridos de extracción de características para poder reducir la dimensionalidad de los datos brutos y la también capacidad que tienen los sistemas para poder manejar condiciones enfocadas al mundo real, como por ejemplo lo pueden ser oclusiones (cuando un objeto bloquea la vista de la mano) y variaciones en la iluminación o escena.\autocite[p.~5]{Hashi2024}

\section{Marco Referencial}

\subsection{Panorama general del reconocimiento de lenguaje de señas}

Como se ha podido evidenciar, la investigación en SLR (reconocimiento de lenguaje de señas) ha ido evolucionando de manera significa, pasando de métodos tradicionales a enfoques avanzados basados en inteligencia artificial, lo que muestra un progreso avanzado en la interacción entre el humano y el computador. Como se pudo apreciar en el apartado anterior con la evolución del campo, se puede segmentar en tres áreas principales de investigación que representan diferentes niveles de complejidad y desarrollo, siendo estas el reconocimiento de señas aisladas, el reconocimiento de señas continuas y por último la traducción del lenguaje de señas.\vspace{0.5cm}\par

En primera instancia, al evaluar las señas aisladas, se ve que esta es la categoría más fundamental del SLR y se enfoca meramente en la identificación de señas individuales que son ejecutadas de manera planeada y con pausas claras entre ellas. Cuando se aborda esta aproximación, se necesita que cada video o secuencia de datos contenga una única seña que debe ser clasificada en una categoría que ya está definida. Por esto es que este tipo de reconocimiento se considera análogo al reconocimiento de gestos estáticos, donde la información sobre la manera en que se presenta la mano es de suma importancia, o en su defecto a los gestos dinámicos simples cuyo movimiento sigue un patrón bien definido y establecido\autocite[p.~2]{Hashi2024}. Como se pudo ver con anterioridad, a lo largo de los años, esta tarea se pudo lograr con éxito usando métodos de aprendizaje automático tradicionales como los Modelos Ocultos de Márkov (HMM), las Máquinas de Vectores de Soporte (SVM) y la Deformación Dinámica del Tiempo (DTW)\autocite[p.~1]{Jiang2024}. Hay que tener en cuenta, a pesar de que el reconocimiento de señas aisladas pudo alcanzar altos niveles de precisión en vocabularios controlados, a la hora de la verdad, su aplicación es muy limitada en la comunicación natural y fluida, porque las personas hablantes no suelen hacer pausas entre cada seña y mucho menos deletrearlas en una conversación normal.\vspace{0.5cm}\par

Por otro lado, cuando se revisa el reconocimiento de señas continuas (CSLR), se puede ver en la revisión documental que representa un salto significativo en complejidad y representa el enfoque de la mayoría de las investigaciones actuales. Cuando se habla de este enfoque, se hace referencia a poder identificar y transcribir una secuencia de señas a partir de un video sin tener que realizarle algún corte, por este motivo, no hay delimitadores marcados entre una seña y la siguiente\autocite[p.~2]{Khan2025}. Por lo anterior, se considera que esta tarea es mucho más complicada y también se pueden identificar dos desafíos principales, siendo el primero de estos, la segmentación temporal, es difícil determinar solo usando código dónde termina una seña y dónde comienza la siguiente en parte por los movimientos de transición que no hacen el cambio de manera evidente\autocite[p.~3]{Khan2025}. Por otro lado, el segundo, es el efecto de co-articulación, donde la apariencia y ejecución de una seña se ven influenciadas por las señas que se hicieron antes y las que se harán después, esto añade una capa extra de variabilidad y complejidad\autocite[p.~14]{Khan2025}. Con esto en mente, para poder abordar estos desafíos, se ha identificado la utilización de los enfoques que están fundamentados en aprendizaje profundo, que utilizan arquitecturas como las Redes Neuronales Convolucionales (CNN) para la extracción de características espaciales y Redes Neuronales Recurrentes (RNN) o Transformers para el modelado temporal\autocite[p.~9]{Khan2025}\autocite[p.~11]{Khan2025}.\vspace{0.5cm}\par

Ahora bien, cuando se habla de la última categoría, que corresponde a la Traducción del Lenguaje de Señas, se dice que es la más complicada, porque diferencia del CSLR, que solo busca transcribir la secuencia de señas, la SLT tiene como objetivo generar una oración gramaticalmente correcta además de tener sentido dentro del contexto de un lenguaje hablado. Teniendo en cuenta lo anterior, se puede deducir que este proceso no solo requiere el reconocimiento preciso de las señas, sino también un profundo entendimiento de la gramática, la sintaxis y la estructura lingüística del lenguaje de señas de origen, así como del lenguaje hablado al que se quiera hacer la traducción. Como se ha podido evidenciar en la investigación, traducir de un lenguaje hablado a uno de señas no solo exige conocimiento del lenguaje, sino también una comprensión de la cultura y el contexto social de sus usuarios. Por esto mismo es que la SLT debe manejar tanto el hecho de que el orden de las señas no siempre corresponde directamente con el orden de las palabras en la oración traducida, como con el hecho de incorporar información crucial transmitida a través de todo el cuerpo del intérprete, como las expresiones faciales y el movimiento del cuerpo, que son parte integral del significado en el lenguaje de señas. En esta área, los casi todos los trabajos de la actualidad, plantean lo anterior como investigaciones futuras o como pasos que ya se han realizado para poder llegar a este ideal, como lo puede ser el reconocimiento de la importancia de capturar todo el intérprete en lugar de solo las manos o la integración de nuevas tecnológicas para encontrar la manera de capturar la temporalidad.\autocite[p.~2]{Akarsh2024}\autocite[p.~23]{Hashi2024}\autocite[p.~11]{Khan2025}.\vspace{0.5cm}\par

Ahora bien, con el panorama general analizado, se puede ubicar este proyecto de investigación dentro de la categoría de Reconocimiento de Señas Continuas (CSLR), con una posible extensión hacia los fundamentos de la Traducción del Lenguaje de Señas (SLT). Esto se puede decir por qué al plantear la naturaleza del lenguaje de señas como un \enquote{sistema lingüístico bastante completo y complejo} que posee \enquote{su propia gramática, vocabulario y estructura sintáctica}, este trabajo de investigación reconoce desde el principio los desafíos que van más allá de la simple clasificación de gestos\autocite[p.~3]{Khan2025}. Además, la investigación se alinea con la corriente principal del CSLR, que se basa en buscar el desarrollo de sistemas capaces de interpretar secuencias de señas en un flujo continuo con videos, enfrentando directamente los problemas de segmentación y co-articulación que caracterizan a esta área\autocite[p.~14]{Khan2025}. Sin embargo, al enfocarse en la estructura del lenguaje, el proyecto sienta las bases para una futura transición hacia la SLT, usando nuevas técnicas en un área que requiere más atención para poder desentrañar el potencial de las herramientas avanzadas de inteligencia artificial.

\subsection{Investigaciones particulares relevantes}

Como se pudo ver en la definición del problema, se presentaron los trabajos más influyentes que inspiraron y moldearon el desarrollo y elección de la técnica que se plantea en esta investigación. No obstante, también hubo otros estudios que de igual manera se enfocan en áreas de interés más particulares para el estudio que sirvieron para probar diferentes teorías más adelante en los análisis de resultados. Esta revisión se inicia con las primeras y más comunes arquitecturas particulares en el reconocimiento de lenguaje de señas y tareas relacionadas, como lo puede ser por ejemplo la lectura de labios, estas se basan en la combinación de Redes Neuronales Convolucionales (CNN) para la extracción de características espaciales y Redes Neuronales Recurrentes (RNN) para el modelado de la dependencia temporal.\vspace{0.5cm}\par

Un ejemplo claro de esta aproximación es el trabajo de Dey et al., quienes proponen una red para el reconocimiento de gestos de preguntas "Wh" en lenguaje de señas americano. En ese estudio, se optó por emplear una arquitectura de Red Convolucional 3D para poder capturar las características espaciales y temporales de bajo nivel directamente de los fotogramas de un video.\autocite[p.~2920]{Dey2024} Posteriormente, se emplea una BiLSTM (Long Short-Term Memory Bidireccional) la cual procesa estas características para entender la secuencia del gesto en ambos sentidos, es decir, hacia adelante y hacia atrás. De igual manera, se incorpora un mecanismo de atención multi-cabeza (Multi-head Attention) el cual permite al modelo establecer la importancia de diferentes partes de la secuencia, mejorando de esta forma, la capacidad de capturar características complejas y relevantes para un reconocimiento mucho más preciso\autocite[p.~2921]{Dey2024}.\vspace{0.5cm}\par

Por otro lado, en otro dominio, siendo más específico en el de la lectura de labios, con el estudio de Inamdar et al. se propone un modelo que también combina convoluciones 3D y una LSTM. Donde se aprovechaba este enfoque híbrido de las CNN 3D para aprender representaciones de video y las LSTM para modelar las secuencias temporales de los movimientos de los labios\autocite[p.~1]{Inamdar2023}. En otra mano, el estudio de Innocente et al. tiene la similitud de seguir esta misma línea para desarrollar un sistema de lectura de labios en italiano con el fin de asistir a pacientes con patologías en las cuerdas vocales\autocite[p.~1]{Innocente2025}. Sin embargo, su modelo consta de una CNN espacio-temporal, la cual se enfoca en un vocabulario específico y cuidadosamente seleccionado para cubrir necesidades de comunicación esenciales y de emergencia, demostrando la aplicabilidad de estas arquitecturas en diferentes entornos con éxito. Además, este estudio también resalta un desafío muy importante en el reconocimiento visual del habla, siendo este la ambigüedad visual donde movimientos de labios similares pueden corresponder a fonemas diferentes (homofenos)\autocite[p.~1]{Innocente2025}.\vspace{0.5cm}\par

También se han analizado enfoques más complejos que buscan superar las limitaciones de los modelos tradicionales con el fin de mejorar la calidad de las representaciones de video. Este cambio de perspectiva se puede ver en la propuesta de Geng et al., quienes abordan el Reconocimiento Continuo de Lenguaje de Señas (CSLR) no como un problema de alineamiento, sino como una tarea de generación de video a texto, teniendo en cuenta que el alineamiento se refiere al categorizar ciertos conjuntos de frames en señas específicas\autocite[p.~1]{Geng2025}. Argumentan que el alineamiento entre los fotogramas del video y las glosas (unidades léxicas del lenguaje de señas) es inherentemente propenso a errores debido a la naturaleza débilmente supervisada de los datos. Para evitar este paso, utilizan un modelo de difusión para generar la secuencia de glosas a partir de las características visuales extraídas. Este enfoque generativo, combinado con aprendizaje contrastivo y mecanismos de atención cruzada (cross-attention), permite al modelo aprender una relación más directa y robusta entre el video y el texto, obteniendo resultados competitivos\autocite[p.~3]{Geng2025}.\vspace{0.5cm}\par

Finalmente, cuando se evalúa el aprendizaje auto-supervisado, se presenta como una solución prometedora para que ya no sea drástica la dependencia a los datos etiquetados de manera masiva. Esto se puede ver con el estudio de Dave et al. el cual se enfoca en desarrollar un TCLR (Temporal Contrastive Learning for Video Representation), a través de un marco de aprendizaje contrastivo diseñado específicamente para datos de video\autocite[p.~1]{Dave2022}. A diferencia de los métodos anteriores, el de TCLR se conoce por introducir explícitamente pérdidas que hacen que el modelo pueda discriminar no solo entre diferentes videos, sino también entre clips no superpuestos dentro del mismo video. Además, esto hace que las características aprendidas sean diversas a lo largo de la dimensión temporal\autocite[p.~6]{Dave2022}. Como resultado, se tienen mejores representaciones de video que impulsan significativamente el rendimiento en tareas posteriores como el reconocimiento de acciones, incluso con etiquetas limitadas. Este enfoque es particularmente importante para el lenguaje de señas, donde se ve que la dinámica temporal y el poder diferenciar entre señas que son visualmente similares es fundamental\autocite[p.~7]{Dave2022}.

\subsection{Research Gap dentro del campo}

Luego de realizar la investigacion del campo, se puede evidenciar que a pesar de los avances significativos en el reconocimiento del lenguaje de señas (SLR), aún hay brechas críticas que no permiten el desarrollo de soluciones robustas y generalizables. Lo anterior se puede sustentar en que una de las principales carencias identificadas es el enfoque común en las tareas de reconocimiento en lugar de representación semántica, lo que se quiere decir con esto es que la mayoría de los trabajos revisados, desde modelos híbridos como C3D-BiLSTM con atención hasta enfoques generativos basados en difusión, están optimizados para la transcripción continua y una posible traducción en el futuro, pero no para el análisis existente de las relaciones semánticas entre señas\autocite[p.~2921]{Dey2024}\autocite[p.~3]{Geng2025}. Lo que se ha evidenciado también es que estas representaciones internas son utilizadas en pro del entrenamiento y no como objetivo principal, es decir, están diseñadas para maximizar la precisión en clasificación, no para organizar el espacio latente según similitudes. Por otro lado, lo que se quiere lograr con este proyecto, se centra explícitamente en la estructuración semántica de palabras en un espacio de baja dimensionalidad, un cambio de paradigma desde la traducción hacia la representación, creando nuevos posibles campos y aproximaciones que se pueden estudiar en el futuro.\vspace{0.5cm}\par

Además, otra brecha detectada es la limitación de los trabajos a contextos monolingües. Es decir, los estudios como los de Jiang (CSL) o Gu (ASL) operan exclusivamente sobre datasets específicos (RWTH-PHOENIX-Weather 2014T, AQSVd), ignorando la diversidad dialectal y la falta de estándares universales en lenguajes de señas al rededor del mundo\autocite[p.~1-40]{Jiang2024}\autocite[p.~1-15]{Gu2024}. Así mismo, como señala Bedoin, los lenguajes de señas varían regionalmente, y su tratamiento como sistemas homogéneos limita su aplicabilidad real a diferentes contextos\autocite[p.~166]{Bedoin2024}. Por eso mismo es que este proyecto aborda este vacío al explorar un espacio latente compartido para tres lenguajes (ASL, indio y ruso), donde señas equivalentes puedan agruparse semánticamente, sentando bases para una futura unificación.\vspace{0.5cm}\par

Siguiendo con lo detectado durante el análisis, resulta llamativo encontrar campos de otras disciplinas que han implementado con éxito soluciones de inteligencia artificial que pueden ser muy valiosas y aún no se han probado en el de lenguaje de señas. Como por ejemplo, la lectura de labios o la rehabilitación motriz donde se han desarrollado técnicas innovadoras que podrían adaptarse, como por ejemplo el trabajo de Inamdar et al. el cual combina CNN 3D y LSTM para modelar movimientos labiales en pacientes con patologías vocales\autocite[p.~1]{Inamdar2023}, mientras que, por otro lado, Innocente et al. emplean arquitecturas espacio-temporales con capas bidireccionales para vocabularios médicos esenciales\autocite[p.~1]{Innocente2025}. A lo que se quiere llegar es que estas aproximaciones centradas en capturar dinámicas temporales y ambigüedades visuales (homofenismos), tienen la particularidad de ser directamente aplicables al SLR, donde la co-articulación y las expresiones faciales son obstáculos que han sido detectados en múltiples escenarios.\vspace{0.5cm}\par

Por último, se detectó un vacío arquitectónico y metodológico en técnicas determinadas. Por esto es que el núcleo de esta investigación reside en una combinación de técnicas que no ha sido explorada anteriormente, esta se compone en primer medida de un Autoencoder Convolucional 3D, el cual es ideal para comprimir videos de señas en representaciones latentes, preservando información espacio-temporal. El cual es evaluado por una función de pérdida compuesta, que se compone de MSE, el cual garantiza reconstrucción confiable de las señas. Que está acompañada de una función Triplet Loss, que su funcionamiento es estructurar el espacio latente mediante distancias semánticas (anclas, positivos y negativos). Acompañada también por una divergencia KL, la cual se encarga de regularizar la distribución latente para evitar sobreajuste y permitir interpolación entre señas. Se dice que no ha sido explorada, porque esta arquitectura difiere de enfoques como TCLR (aprendizaje contrastivo temporal), que diferencian clips pero no organizan el espacio semánticamente\autocite[p.~6]{Dave2022}. Además, de integrar investigaciones con otros objetivos como de modelos médicos, como puede ser la lectura de labios, o de producción de señas, como el modelo G2P-DDM para generación de poses\autocite[p.~6234]{Xie2024}, pero organizada bajo un único objetivo, el cual es poder mapear señas multilingües en un espacio estructurado.\vspace{0.5cm}\par

En conclusión, se pudo identificar que las brechas observadas revelan que el SLR está lejos de ser perfeccionado o estar en una etapa final. Esto por los diferentes enfoques centrados en representación, no solo reconocimiento. Además de no tener modelos multilingües destacables que capturen diversidad dialectal. Sin mencionar que faltan arquitecturas híbridas que combinen técnicas de aprendizaje autosupervisado y regularización semántica bajo funciones de perdida determinadas. Sin duda alguna, este proyecto llena un vacío crítico al proponer un marco para analizar y visualizar relaciones entre señas de distintos lenguajes, utilizando recursos limitados pero estratégicos (datasets ASL, indio y ruso). Donde los resultados podrían guiar futuras investigaciones hacia sistemas de traducción universal más inclusivos, alineados con las necesidades reales de las comunidades sordas\autocite[p.~851]{Adler2025}.\vspace{0.5cm}\par

\section{Marco Conceptual}

\subsection{Fundamentos Lingüísticos y Culturales del Lenguaje de Señas}

En esta subsección se aborda la naturaleza del lenguaje de señas visto como un sistema lingüístico complejo y además el pilar de una cultura compleja.

\begin{itemize}

\item Lenguaje de Señas como Sistema Lingüístico.\vspace{0.5cm}\par

Es un sistema de comunicación natural, completo y complejo, utilizado por las comunidades sordas. No obstante, no consiste en una simple serie de gestos, sino que más bien en poseer todos los componentes de una lengua, siendo estos la gramática, sintaxis y un léxico rico. Además, su estudio requiere un enfoque interdisciplinario que integre la lingüística con el análisis cultural para su mejor comprensión.

\item Parámetros Constituyentes.\vspace{0.5cm}\par

Son los cinco componentes fundamentales que constituyen una seña individual. Es decir, las características que dan información respecto a ella, que cuando se da una alteración de cualquiera de estos parámetros, se puede cambiar por completo el significado de la seña.

\textbf{\small Configuración Manual: }La forma específica que adopta una mano al realizar una seña, como por ejemplo, el puño cerrado o los dedos extendidos.

\textbf{\small Ubicación: }El lugar en el cuerpo o, en su defecto, en el espacio donde se ejecuta la seña, como por ejemplo en la frente o en el pecho.

\textbf{\small Movimiento: }La acción o trayectoria que realizan las manos o partes del cuerpo durante la ejecución de la seña, como lo pueden ser el movimiento circular o la línea recta.

\textbf{\small Orientación de la Palma: }La dirección hacia la cual apunta la palma o los dedos de la mano, como por ejemplo, hacia arriba, hacia abajo o incluso hacia el intérprete.

\textbf{\small Componentes no Manuales: }Incluyen expresiones faciales, como lo puede ser una ceja levantada para una pregunta, movimientos de la cabeza, la boca o el torso. Se evidencia que estos componentes son muy importantes, ya que son capaces de cumplir un papel importante en la interpretación, pudiendo añadir matices emocionales o hasta intensificar el significado.

\item Diversidad Lingüística del Lenguaje de Señas.\vspace{0.5cm}\par

\textbf{\small Mito del Lenguaje de Señas Universal: }Se refiere a la creencia errónea que se tiene de que existe un único lenguaje de señas para todas las personas sordas del mundo. De hecho, en realidad, existen cientos de lenguajes de señas distintos, siendo más de 200 documentados como se ha visto en la investigación, donde cada uno cuenta con su propia historia y evolución, como por ejemplo la evolución histórica que se estudió del Lenguaje de Señas Americano con relación al Lenguaje de Señas Francés.

\textbf{\small Dialectos y Regionalismos: }Al igual que los idiomas hablados, los lenguajes de señas presentan variaciones en su dialecto. Esto quiere decir que en una misma seña se puede tener formas ligeramente diferentes o pueden existir señas distintas y que estas tengan un mismo concepto dependiendo de la región geográfica, como por ejemplo las diferencias en el lenguaje entre Bogotá y la costa.

\item Cultura Sorda\vspace{0.5cm}\par

Esta es el conjunto de creencias, comportamientos, arte, tradiciones literarias, historia y valores compartidos por las comunidades de personas que se han visto afectadas por una discapacidad auditiva. Esto quiere decir que el lenguaje de señas no es solo una herramienta de comunicación, sino el pilar central que porta y preserva esta identidad cultural.

\item Bilingüismo Bimodal y Multilingüismo\vspace{0.5cm}\par

\textbf{\small Bilingüismo Bimodal: }Se refiere al dominio y uso de un lenguaje de señas, es decir, en la modalidad de gestos, y un lenguaje hablado o escrito, es decir, en modalidad oral o auditiva, por parte de un usuario.

\textbf{\small Multilingüismo en Comunidades Sordas: }Esto quiere decir que se reconoce, particularmente en contextos multiculturales o en casos como los migratorios, donde las personas sordas pueden llegar a dominar múltiples lenguajes de señas o, en su defecto, combinaciones de estos con varias lenguas orales.

\end{itemize}

\subsection{Perspectivas sobre Discapacidad, Accesibilidad e Inclusión}

En esta subsección se enmarca el proyecto dentro de un contexto social, destacando de esta manera las barreras que enfrentan las personas sordas y también la importancia de las soluciones tecnológicas.

\begin{itemize}

\item Modelo Social de la Discapacidad\vspace{0.5cm}\par

Es una perspectiva que entiende lo que es la discapacidad no como una deficiencia inherente al individuo, sino más bien como el resultado de las barreras sociales, culturales, actitudinales y físicas que pueden impedir la participación plena de las personas, por ejemplo, la exclusión de una persona sorda no se debe a su sordera, sino más bien a la falta de intérpretes, de tecnologías accesibles o de conciencia social.

\item Accesibilidad y Diseño Universal\vspace{0.5cm}\par

\textbf{\small Accesibilidad: }Se refiere al diseño de productos, servicios o entornos para que puedan ser utilizados por el mayor número posible de personas, independientemente de sus capacidades. Sin embargo, en el contexto tecnológico, esto implica crear herramientas que eliminen las barreras de comunicación.

\textbf{\small Diseño Universal: }Va un paso más allá de la accesibilidad, donde realmente se enfoca en la creación de soluciones que atiendan a la diversidad humana desde su creación, sin la necesidad de adaptaciones posteriores, como lo puede ser una app que está diseñada desde el inicio con opciones de visualización bastante flexibles que no requieran de más actualizaciones.

\end{itemize}

\subsection{Barreras de Accesibilidad e Impacto de la Falta de Conciencia}

Esta subsección menciona la falta de recursos accesibles y de conciencia sobre la cultura sorda, lo cual genera barreras sistemáticas que impactan negativamente la vida de las personas sordas en ámbitos académicos, profesionales y de salud. Esto significa en su exclusión, falta de independencia, y puede generar sentimientos de frustración, ansiedad y agotamiento emocional.

\subsection{Contexto Histórico de la Educación de Sordos}

Esta subsección se encarga de añadir una perspectiva histórica muy importante para entender los conflictos y valores dentro de la comunidad sorda.

\begin{itemize}

\item Oralismo vs. Método Manual\vspace{0.5cm}\par

\textbf{\small Oralismo: }Es un enfoque educativo, históricamente dominante tras el Congreso de Milán de 1880, el cual prioriza la enseñanza del habla y la lectura de labios, frecuentemente prohibiendo el uso del lenguaje de señas.

\textbf{\small Método Manual: }Es el que defiende el uso del lenguaje de señas y lo establece como el método principal y más natural para la educación de las personas con alguna discapacidad.

\item Resiliencia Comunitaria\vspace{0.5cm}\par

Se refiere a las estrategias de las comunidades sordas para preservar su lengua y cultura frente a la opresión, como la ocurrida frente al oralismo, como se puede apreciar en las películas de la National Association of the Deaf en EE.UU., que se encargaron de documentar el ASL para futuras generaciones.

\end{itemize}

\section{Marco Teórico}

\subsection{Teoría del Aprendizaje por Representación (Pilar Central)}
 
Cuando se habla del aprendizaje por representación, se hace referencia a que es el paradigma fundamental de esta investigación. Esto se dice porque su objetivo no es solo predecir, sino más bien aprender transformaciones de los datos que extraigan información útil para la realización de tareas. Cuando se toma esta aproximación, ya no se enfoca en operar sobre los píxeles brutos de un video, es decir, que el modelo aprende una nueva representación en un espacio vectorial de menor dimensionalidad, conocido como espacio latente.\vspace{0.5cm}\par

En esta teoría se establece la piedra angular del proyecto, ya que el problema se enfoca explícitamente en \enquote{el comportamiento y la organización de las palabras dentro de un determinado espacio vectorial de baja dimensionalidad}. Asi mismo, la elección de un autoencoder como núcleo de la arquitectura es una consecuencia directamente a esta teoría, se toma esta decisión también teniendo en cuanta que el modelo se entrena no para clasificar, sino más bien en comprimir una seña en una representación latente y luego reconstruirla. Por ende, la calidad y estructura de esta representación es el verdadero objetivo, pues se teoriza que en este espacio las relaciones semánticas entre señas, incluso de diferentes idiomas, se harán evidentes.

\subsection{El Principio del "Information Bottleneck" (IB) y la Teoría de Modelos Generativos}

En un principio, el principio del "Information Bottleneck" (IB) muestra que una representación ideal debe ser un "cuello de botella" para la información, esto quiere decir que se debe comprimir al máximo la entrada reteniendo solo la información que es relevante. Cuando se transporta al contexto del autoencoder, esto se puede traducir en un equilibrio entre compresión, una representación simple, y preservación de la información, una reconstrucción precisa. Por lo tanto, este proyecto integra el IB a través de la función de pérdida compuesta, es decir que el Error Cuadrático Medio (MSE) asegura la fidelidad de la reconstrucción, mientras que la Divergencia de Kullback-Leibler (KL) la fuerza a que las representaciones latentes sigan una distribución simple, actuando como un regularizador que estructura el espacio y evita la memorización.\vspace{0.5cm}\par

Por otro lado, la teoría de los Modelos Generativos, muestra que al utilizar un Autoencoder Variacional, el modelo no es solo de compresión, sino más bien generativo. Esto significa que no solo aprende a codificar y decodificar, sino que también aprende la distribución de probabilidad subyacente de los datos. Con esta perspectiva se tiene un enfoque más poderoso, ya que este implica que el modelo entiende todo lo que compone de una seña, pudiendo teóricamente generar nuevas instancias de señas visualmente coherentes. Además, esta capacidad generativa sirve como una validación para mostrar que el espacio latente ha sido capas de capturar la estructura fundamental de los datos.

\subsection{Teoría del Aprendizaje por Transferencia (Transfer Learning)}

Cuando se habla de esta teoría, se dice que es una adición fundamental para poder justificar el objetivo de la unificación global. Esto se puede afirmar, porque el Transfer Learning se enfoca en aprovechar el conocimiento adquirido en una tarea o dominio para mejorar el rendimiento en otro.\vspace{0.5cm}\par

Con lo anterior claro, se puede traer a colación el problema de la escasez de datasets etiquetados a gran escala, siendo esta una limitación crítica en el campo. Por otro lado, no es viable crear un dataset masivo para cada uno de los 200+ lenguajes de señas, por este motivo, la teoría del aprendizaje por transferencia, es ideal al entrenar el autoencoder en un lenguaje de señas de gran escala usando aprendizaje auto-supervisado. Donde la importancia reside en esta fase, en la cual el modelo aprenderá características universales sobre el movimiento humano y la gesticulación.

\subsection{Teorías de Aprendizaje Auto-Supervisado (SSL) y Métrico (Metric Learning)}

Cuando se habla de estas dos teorías, se puede ver que ambas definen la estrategia de entrenamiento para aprender representaciones semánticas sin necesidad de etiquetas masivas.\vspace{0.5cm}\par

Con más detalle, se ve que el aprendizaje Auto-Supervisado (SSL) es una respuesta estratégica a la escasez de datos etiquetados a nivel de frame. Donde el propio dato de entrada proporciona la supervisión, en cambio, la elección de la reconstrucción de video como tarea de pretexto es una implementación directa de SSL. Al utilizarlo, esto permite que el modelo aprenda características espaciotemporales de manera autónoma.\vspace{0.5cm}\par

Por otro lado, el aprendizaje Métrico y la Función de Pérdida Triplet es el mecanismo clave para poder organizar el espacio latente por su significado. Mientras que el SSL aprende el cómo se ve una seña, el aprendizaje métrico le enseña al modelo, qué significa. Como se puede ver, la Pérdida Triplet estructura el espacio de una manera que las representaciones de señas semánticamente similares, siendo estas el ancla y el positivo, por ejemplo "gracias" en ASL y "gracias" en LSC, estén más cerca que las de señas no relacionadas, siendo estas el ancla y el negativo, por ejemplo "gracias" y "lunes" en ASL. Por otra parte, esta teoría es muy importante para poder superar las variaciones o ruido superficial, como lo puede ser diferente, iluminación, ropa del intérprete, o incluso el idioma, para poder agrupar las señas por su equivalencia semántica.

\subsection{Modelado de Características Espacio-Temporales y la Hipótesis del Múltiple}

Por otro lado, estas teorías justifican la arquitectura de red neuronal específica que se eligió para el proyecto. Siendo esta el modelado de características espaciotemporales, donde el lenguaje de señas se caracteriza por ser intrínsecamente dinámico y para poder abordar estas características se emplea una arquitectura híbrida. La cual se conforma por un autoencoder convolucional 3D (3D-CNN), el cual extrae características locales que son capaces de fusionar el espacio y tiempo a corto plazo, es decir la forma de la mano mientras se mueve. Y una red neuronal recurrente (GRU) bidireccional, la cual se encarga de modelar las dependencias temporales a largo plazo, capturando de esta manera el contexto completo de la seña al procesar la secuencia de características en ambas direcciones. Teniendo en cuenta lo anterior, esta arquitectura determinada está teóricamente diseñada para ser capas de poder capturar desde los movimientos más pequeños hasta la estructura narrativa más completa de un gesto.\vspace{0.5cm}\par

Por otro lado, también se tiene la hipótesis del múltiple (Manifold Hypothesis), donde esta hipótesis señala que los datos de alta dimensionalidad del mundo real, como lo pueden ser los píxeles de un video en este caso, en realidad se encuentran en una estructura subyacente de baja dimensionalidad (un manifold). Este proyecto se basa en la presunción de que todos los videos posibles de la seña \enquote{aprender}, sin importar sus muchos píxeles que la componen, se pueden agrupar en una pequeña región de este manifold. Donde, en este caso, el objetivo del autoencoder es precisamente descubrir y parametrizar este manifold, utilizando las herramientas de visualización como UMAP y t-SNE. Por tanto, estas últimas herramientas, cuentan como métodos para validar empíricamente esta hipótesis, permitiendo analizar si el modelo ha sido capas de aprender una estructura coherente donde las señas se organizan de manera lógica.

\section{Marco Tecnológico y científico}

\subsection{Tecnología para el Procesamiento del Lenguaje de Señas}

\begin{itemize}

\item Reconocimiento de Lenguaje de Señas por Computadora\vspace{0.5cm}\par

\textbf{\small Reconocimiento de Señas Aisladas (ISLR): }Es la tarea de identificar señas individuales que se realizan con pausas claras y marcadas entre ellas. Además, es una aproximación más sencilla, pero limitada a determinados entornos controlados.

\textbf{\small Reconocimiento Continuo de Lenguaje de Señas (CSLR): }Esta es la tarea de transcribir una secuencia continua y fluida de señas, la cual puede ser una frase, una conversación o inclusive, como en el contexto de este proyecto, palabras que están compuestas por varios movimientos, a partir de un video. Esta es mucho más desafiante debido a la falta de pausas y la co-articulación.

\textbf{\small Traducción del Lenguaje de Señas (SLT): }Por otro lado, esta representa el objetivo final de muchos trabajos, que no solo reconoce las señas, sino que las convierte a texto, voz u otro medio de comunicación, en un idioma hablado, respetando las diferencias gramaticales y sintácticas entre ambas lenguas.

\item Desafíos Fundamentales en CSLR\vspace{0.5cm}\par

\textbf{\small Alineamiento Débilmente Supervisado: }Este representa un problema bastante común donde se dispone de un video y su transcripción textual completa, pero no de una correspondencia exacta y minuciosa, siendo este dicho el alineamiento entre cada fotograma y la seña específica, dificultando el entrenamiento de los modelos.

\textbf{\small Segmentación Temporal: }Esta es la dificultad de identificar dónde termina una seña y comienza la siguiente en un flujo continuo.

\textbf{\small Co-articulación: }Este es el fenómeno donde la ejecución de una seña es influenciada por las señas que van antes y después.

\textbf{\small Limitaciones de Datasets: }Es la escasez de conjuntos de datos públicos, grandes, diversos y de alta calidad, que representen todos dialectos y variaciones culturales.

\textbf{\small Robustez en Condiciones Reales: }Es la dificultad de los sistemas para manejar oclusiones, es decir, manos bloqueadas por algún otro elemento, variaciones de iluminación, fondos complejos y diferencias individuales en la manera de realizar las señas.

\end{itemize}

\subsection{Tecnología para el Procesamiento del Lenguaje de Señas}

\begin{itemize}

\item Redes Neuronales para Extracción de Características\vspace{0.5cm}\par

\textbf{\small Red Neuronal Convolucional (CNN): }Está diseñada para procesar datos en formato de rejilla como las imágenes. También se utiliza para la extracción de características espaciales, como formas o texturas de los fotogramas de un video.

\textbf{\small Red Neuronal Convolucional 3D (3D-CNN o C3D): }Esta es una configuración de la CNN que tiene la particularidad de operar sobre volúmenes de datos que tienen el formato alto x ancho x tiempo, que además tiene la capacidad de capturar simultáneamente características espaciales y temporales, haciéndola ideal para el movimiento entre fotogramas y para el análisis de gestos dinámicos.

\item Redes Neuronales para el Modelado de Secuencias\vspace{0.5cm}\par

\textbf{\small Red Neuronal Recurrente (RNN): }Esta está diseñada para procesar datos secuenciales al tener una memoria que le permite usar información de pasos anteriores para cambiar la salida actual.

\textbf{\small Red Neuronal Long Short-Term Memory (LSTM) y BiLSTM: }Esta red tiene la particularidad de estar diseñada para procesar datos secuenciales, que como sucede con la RNN, tiene una memoria que le permite usar información de pasos anteriores para cambiar la salida actual. Sin embargo, lo que diferencia a la LSTM es que es una RNN avanzada que puede resolver el problema de aprender dependencias a largo plazo. Por otro lado, una BiLSTM es aquella que procesa la secuencia en ambas direcciones, es decir, hacia adelante y hacia atrás, proporcionando de esta manera un contexto temporal más completo.

\item Arquitecturas de Aprendizaje de Representación\vspace{0.5cm}\par

\textbf{\small Autoencoder: }Es una arquitectura no supervisada que aprende a comprimir datos, es decir, una codificación en una representación de baja dimensionalidad llamada espacio latente, para luego reconstruir la entrada original, es decir una decodificación. Donde su objetivo es el aprendizaje de características y la reducción de dimensionalidad.

\textbf{\small Autoencoder Convolucional 3D (3D-CAE): }Es una implementación específica del autoencoder que usa capas convolucionales 3D para poder comprimir videos, capturando de esta manera patrones espaciotemporales de una manera eficiente.

\textbf{\small Transformer: }Esta es una arquitectura avanzada que utiliza mecanismos de atención para poder procesar contextos largos y capturar de esta manera relaciones complejas entre elementos de una secuencia, superando algunas limitaciones de las RNNs.

\item Mecanismo de Atención (Attention Mechanism)\vspace{0.5cm}\par

Este es un componente importante que permite a un modelo neuronal ponderar de manera dinámica la importancia de diferentes partes de una secuencia de entrada al generar una salida determinada. Es decir, en lugar de tratar todos los fotogramas o características por igual, el modelo aprende a prestar atención a los segmentos que tienen más relevancia.

\end{itemize}

\subsection{Estrategias de Aprendizaje, Optimización y Evaluación}

\begin{itemize}

\item Paradigmas de Aprendizaje\vspace{0.5cm}\par

\textbf{\small Aprendizaje Auto-Supervisado (Self-Supervised Learning): }Este es un paradigma donde el modelo puede aprender representaciones significativas directamente de los datos sin la necesidad de etiquetas manuales. Además, esta tarea se logra mediante la creación de tareas pretexto, como por ejemplo predecir un frame determinado que está más adelante en la secuencia.

\textbf{\small Aprendizaje Contrastivo (Contrastive Learning): }Este es un enfoque del aprendizaje auto-supervisado que se encarga de enseñar al modelo la creación un espacio de representación donde las muestras similares, como lo pueden ser dos clips de la misma seña, están juntas, y las muestras diferentes, como lo pueden ser videos de señas diferentes, están separadas.

\textbf{\small Temporal Contrastive Learning (TCLR): }Esta es una implementación específica para videos que se encarga de asegurarse que el modelo pueda aprender características diversas a lo largo del tiempo de entrenamiento.

\item Función de Pérdida Compuesta (Composite Loss Function)\vspace{0.5cm}\par

\textbf{\small Error Cuadrático Medio (MSE): }Esta metrica, es la que mide la diferencia promedio al cuadrado entre la entrada original y la reconstruida por el autoencoder, forzando una reconstrucción fiel.

\textbf{\small Pérdida Triplet (Triplet Loss): }Esta es una función de perdida que opera sobre un triplete, el cual está constituido de una ancla, un elemento positivo y uno negativo para estructurar semánticamente el espacio latente, minimizando de esta manera la distancia entre señas de la misma clase y maximizando la distancia entre señas de clases diferentes.

\textbf{\small Divergencia de Kullback-Leibler (KL): }Esta se encarga de desempeñar un papel como un término de regularización para forzar que el espacio latente se ajuste a una distribución de probabilidad conocida como lo puede ser la normal, resultando en un espacio más suave y bien organizado, evitando el sobreajuste.

\item Técnicas de Reducción de Dimensionalidad y Visualización\vspace{0.5cm}\par

\textbf{\small UMAP / t-SNE: }Estos son algoritmos utilizados para poder visualizar el espacio latente de alta dimensionalidad en un gráfico 2D o 3D. Se usan en el proyecto, ya que tienen la particularidad de permitir la inspección visualmente de si el modelo ha logrado agrupar señas similares.

\end{itemize}
