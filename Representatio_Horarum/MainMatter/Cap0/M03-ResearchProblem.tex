
\section*{Panorama del lenguaje de señas}

Mediante una investigación, se pudo evidenciar que el lenguaje de señas abarca un campo de estudio de gran relevancia y tamaño que ha sido abordado a lo largo de los años desde múltiples disciplinas, las cuales incluyen la lingüística, la sociología, la antropología y las ciencias de la computación, entre otras más. Esta aproximación multidisciplinaria va acorde a su naturaleza como un sistema lingüístico bastante completo y complejo, que va más allá de la percepción que usualmente se tiene de ser únicamente una serie de gestos manuales y sistemáticos\autocite[p.~216]{Probierz2023}. Esta profundidad surge en parte por la diversidad y contexto en el que se desarrolla \enquote{There are many different sign languages in the world, each with its own unique characteristics. Therefore, translating from a national language into a sign language requires not only knowledge of the sign language, but also an understanding of the culture and social context of the people who use it}\autocite[p.~213]{Probierz2023}. Además, como sugiere Probierz, como sistema lingüístico natural, el lenguaje de señas posee su propia gramática, vocabulario y estructura sintáctica, lo que requiere un enfoque interdisciplinario que integre la lingüística con el análisis cultural para poder entender toda su complejidad\autocite[p.~213]{Probierz2023}.\vspace{0.5cm}\par

No obstante, esta complejidad aumenta bastante al considerar que, a pesar de lo que las personas piensan comúnmente, no existe un lenguaje de señas universal. Tan solo en Estados Unidos, de los 30 millones de personas con pérdida auditiva, únicamente 6 millones utilizan el ASL, y entre esos, solo 2 millones son usuarios activos.\autocite[p.~851]{Adler2025} A nivel mundial, la situación se vuelve más complicada y fragmentada, teniendo más de 200 lenguajes de señas distintos. Esta diversidad, si bien es un reflejo de la riqueza cultural, representa un gran obstáculo significativo para la comunicación global. Además, la falta de recursos accesibles se convierte en una barrera sistemática que contribuye a que las personas con discapacidades queden atrasadas respecto a sus pares sin discapacidades en la búsqueda de una carrera profesional, como ocurre en STEMM\autocite[p.~851]{Adler2025}.\vspace{0.5cm}\par

Estableciendo que el lenguaje es un constructo profundo, con múltiples capas en su origen y por ende en su significado, donde el componente cultural desempeña un papel fundamental como uno de los pilares centrales en su constitución. Se puede analizar que en el caso de las lenguas de señas, estas no solo funcionan como un sistema de comunicación, sino que también encarnan una identidad y una cultura propias, enriquecidas por diferentes elementos históricos, sociales y educativos que complementan y construyen su complejidad\autocite[p.~166]{Bedoin2024}. Además, para entender el lenguaje de señas, también es importante analizar la sordera desde sus diferentes componentes \enquote{Deafness as a historical and social phenomenon is analysed through an interdisciplinary approach, including Deaf history, Sign language, Deaf culture, Deaf identity, Deaf education, etc.}\autocite[p.~163]{Bedoin2024}. Con relación a lo anterior, el lenguaje de señas se conecta y puede abordar desde diferentes puntos de vista que lo componen para desentrañar su complejidad, como cualquier otra forma de comunicación entre humanos, van más allá de la sola funcionalidad de comunicar para ser en un pilar de la identidad cultural de las comunidades sordas a través del mundo\autocite[p.~163]{Bedoin2024}.\vspace{0.5cm}\par

Siguiendo ese orden de ideas, las lenguas de señas no son muy diferentes de las orales, porque ambas están ligadas a variaciones dialécticas que son un reflejo de la diversidad en la cultura de las diferentes regiones de los hablantes. Cuando se habla de variaciones, se hace referencia a acentos, regionalismos y otras expresiones lingüísticas que enriquecen la diversidad del lenguaje\autocite[p.~162]{Bedoin2024}. Con lo anterior claro, ya no es descabellado pensar que el Lenguaje de Señas Colombiano (LSC) presenta diferencias entre regiones, como entre la región del pacífico y de la capital, siguiendo la lógica del español que se habla allí, donde se pueden notar grandes diferencias en los acentos de los habitantes de estas áreas. Este concepto antes descrito se conoce como la diversidad dialectal en las lenguas de señas, este se alinea con el reconocimiento de la multilingualidad en los distintos estudios dirigidos a personas con discapacidad auditiva, en los cuales se ha podido observar que está ocurriendo un cambio dentro el estudio de múltiples lenguas, los cuales tienen en cuenta las lenguas de señas heredadas\autocite[p.~166]{Bedoin2024}. Este cambio se ha podido observar en diferentes estudios \enquote{Scholars often conducted their studies on a single pair of languages (e.g. English and ASL). The interest in bimodal bilingualism has recently shifted towards multilingualism (Swanwick 2016), including heritage spoken and sign languages}\autocite[p.~163]{Bedoin2024}. Lo que implica que cada vez es más fácil, al tener más estudios en esta área y enfoque, sustentar que las lenguas de señas no son homogéneas, sino que, por el contrario, estas tienen ciertas variaciones que, como se establece con anterioridad, son un reflejo de la riqueza lingüística y cultural de las comunidades con alguna discapacidad de tipo auditivo. Es por eso que también se pueden plantear posibles conflictos relacionados con problemas sociales actuales, como lo puede ser el incremento de la migración, donde las lenguas heredadas pueden jugar un papel esencial, al significar choques culturales entre la lengua establecida en el territorio y la que ha tenido que desplazarse e integrarse al mismo.\vspace{0.5cm}\par

Por lo cual, cuando se empieza a ver las lenguas de señas desde otra perspectiva y no solo como herramientas comunicativas, se puede ver que constituyen un componente muy importante de la identidad cultural de las diferentes comunidades con discapacidad al rededor del mundo. Entonces, cuando se tiene esta identidad, que va más allá de las limitaciones físicas y se construye a partir de una comunidad que históricamente se ha desarrollado como ninguna otra por sus diferentes condiciones de vida y contextos, se puede ver que en realidad abarca un área inmensamente diversa de experiencias culturales y lingüísticas. Como indica Bedoin \enquote{Deaf people have long been considered members of a unique and uniform community – with a Sign Language, a Deaf culture and a Deaf identity. This leads to the affirmation of a homogeneous or even a universal Deaf culture from which a strong Deaf identity plays a positive role in the recognition of Deaf communities around the world}\autocite[p.~163]{Bedoin2024}.

\section*{El problema con el lenguaje de señas}

No obstante, a pesar de todas las investigaciones que se han realizado desde diferentes perspectivas, aún no se ha llegado a una solución efectiva del problema, esto solo genera una mayor falta de sensibilización y el surgimiento de etiquetas equivocadas que se le asignan tanto al lenguaje como a las personas involucradas siendo consecuencias mayormente significativas para las PDHL (People Disabling Hearing Loss), especialmente en el acceso a servicios de salud, lo cual es contradictorio, pues debería ser este campo el que tuviera este problema cubierto en mayor medida.\vspace{0.5cm}\par

La falta de conciencia sobre la perdida de audición puede resultar en experiencias negativas que afectan la independencia, la confianza y el bienestar psicológico de las personas que poseen esta discapacidad\autocite[p.~7]{Parmar2025}. Así mismo, es importante destacar cómo la falta de ciertos ajustes al sistema y la necesidad constante de justificarse por sí mismas generan frustración y agotamiento emocional en las personas con esta discapacidad. \enquote{Respondents in this study detailed their experiences during NHS clinical consultations, highlighting how the lack of deaf awareness has adversely impacted their access to services, independence, confidence, and psychological well-being. Additionally, they reported feeling a perceived responsibility to self-advocate to secure a better standard of care.}\autocite[p.~14]{Parmar2025}\vspace{0.5cm}\par

Así mismo, estos problemas se identifican en el área académica y profesional, incluso en las interacciones informales, o en espacios profesionales para fomentar el networking y el aprendizaje colaborativo, donde frecuentemente excluyen a las personas con discapacidad, ya que las ayudas visuales propuestas como las auto-capturas o la escritura resultan insuficientes ante la rapidez y complejidad de estas conversaciones\autocite[p.~852]{Adler2025}. De igual manera, un científico discapacitado puede encontrarse constantemente en una dinámica de "ponerse al día", en la cual, cuando logra entender toda la información y des atrasarse, sus compañeros de trabajo con la capacidad de escuchar ya han avanzado bastante en la discusión, empeorando una brecha de conocimiento que afecta directamente su competitividad, en un escenario real que puede ser el obtener financiación en sus investigaciones, especialmente si deciden ser independientes\autocite[p.~852]{Adler2025}. De igual manera, la falta de intérpretes de ASL, y posiblemente cualquier lenguaje de señas, con conocimientos técnicos en áreas especializadas hace mucho peor esta situación, donde se sufre el riesgo posible de caer en malas interpretaciones o traducciones que pueden ser críticas en un contexto científico.\autocite[p.~853]{Adler2025}.\vspace{0.5cm}\par

Igualmente, las personas con discapacidad mencionaron con urgencia que tienen sentimientos de ansiedad, humillación y miedo a no poder transmitir información vital debido a barreras del lenguaje, lo que en los peores escenarios lleva a las personas evitar la atención médica. \enquote{The way I have been treated whenever I have needed to attend either a hospital or doctor’s appointment makes me scared to go on my own and I tend to avoid contacting the health services even when it’s likely I need them.} \autocite[p.~11]{Parmar2025}\vspace{0.5cm}\par

Teniendo en cuenta las experiencias de las personas que tienen esta discapacidad, que muestran cómo los malentendidos, en su forma de comunicarse usando el lenguaje de señas, no solo impulsan el uso de etiquetas erróneas, sino que también, como se aborda en el estudio citado, a potenciar desigualdades en la atención médica, afectando la calidad de vida de las PDHL. Además de revisar la importancia cultural y significativa que puede tener algo tan profundo a la comunidad como lo es el lenguaje. Se decide abordar el problema de la barrera del idioma en el lenguaje de señas, principalmente por lo mencionado anteriormente, entre otros motivos que se abordan en la justificación y marco teórico. Con la intención de poder aportar a futuras investigaciones que a través de ciertas técnicas de inteligencia artificial puedan llegar a crear soluciones efectivas que impulse la unificación del lenguaje de señas a nivel global.\vspace{0.5cm}\par

\section*{Indagación de estudios previos con el lenguaje de señas}

Ahora bien, con un problema definido que se quiere solucionar, se realiza una investigación al estado del arte relacionado con la integración de tecnologías avanzadas, como la inteligencia artificial, el aprendizaje automático y el procesamiento del lenguaje natural con el lenguaje de señas para poder encontrar un campo que no haya sido trabajo de manera exhaustiva, identificando lo que se realizó y cuál es la importancia que cada estudio puede aportar. Es importante precisar que no se mencionaran todos los estudios consultados en este apartado, pues además de ser bastante extenso y perder la cohesión entre los argumentos, solo se quiere mencionar a los principales estudios que más adelante moldearían el curso de la investigación y el cómo se llegó a una pregunta de investigación bien delimitada, los demás estudios serán referenciados en el marco teórico.\vspace{0.5cm}\par

Al revisar el estudio \enquote{A Survey on Chinese Sign Language Recognition: From Traditional Methods to Artificial Intelligence}\autocite[p.~1-40]{Jiang2024} podemos ver que esencialmente se trata de una revisión exhaustiva de las metodologías y tecnologías empleadas en el reconocimiento de la Lengua de Señas China (CSL) a lo largo de los últimos 20 años. Lo realiza haciendo especial énfasis en la evolución de los métodos, desde enfoques tradicionales hasta innovaciones basadas en inteligencia artificial.\vspace{0.5cm}\par

Inicialmente, durante la realización del estudio se utilizaron Modelos Ocultos de Markov (HMM) y Máquinas de Vectores de Soporte (SVM), las cuales se centraban en la clasificación de gestos a partir de determinadas características extraídas, así como la estrategia Dynamic Time Warping (DTW), la cual permitía alinear secuencias de gestos con variaciones en la velocidad. Sin embargo, en la última década, la investigación cambio su punto de vista, ahora hacia Redes Neuronales Profundas (DNN), que han demostrado ser muy importantes para mejorar la precisión y robustez del reconocimiento de gestos, por otro lado, la implementación de modelos híbridos que combinan diferentes arquitecturas para optimizar el rendimiento también han demostrado ser de gran utilidad.\vspace{0.5cm}\par

Además, el estudio también abarca la exploración de la integración de múltiples modalidades, lo anterior quiere decir que, busca fusionar características tanto de gestos como con expresiones faciales y con movimientos de labios, lo que demostró ser crucial para una interpretación más precisa y fiel del lenguaje de señas. Teniendo todo lo anterior en cuenta, los objetivos de esta investigación no solo van hasta mejorar la precisión y robustez de los sistemas de reconocimiento, sino que también desarrollar conjuntos de datos más grandes y estandarizados para que se pueda facilitar el entrenamiento de modelos, así como promover aplicaciones prácticas que hagan accesible esta tecnología al público general. No obstante, a pesar de los avances significativos que se mencionan, el documento también registra que hay desafíos que no se han podido superar aún, como lo es la fusión de características de lengua de señas continuas y la coordinación de gestos con expresiones faciales, incluso señalando la necesidad de mejorar la robustez y el rendimiento de este tipo de algoritmos en tiempo real. En conclusión, se puede prever que el continuo desarrollo de nuevas tecnologías y la integración de diferentes campos científicos impulsarán aún más de forma positiva el reconocimiento de la lengua de señas china, con un énfasis determinado en modelos híbridos y diferentes técnicas de aprendizaje profundo, lo que promete generar un futuro mucho más accesible y efectivo para las todas aquellas personas con discapacidades auditivas.\vspace{0.5cm}\par

Por otro lado, al revisar el estudio \enquote{A Systematic Review of Hand Gesture Recognition: An Update From 2018 to 2024}\autocite[p.~1-35]{Hashi2024} se puede ver que este presenta una revisión sistemática de la literatura sobre el reconocimiento de lenguaje de señas, haciendo énfasis especial en los métodos de visión, sensores y enfoques híbridos que se han utilizado entre 2018 y 2024.\vspace{0.5cm}\par

Cuando se revisa en profundidad, este muestra que la metodología del estudio se basa en un proceso estructurado que incluye primeramente la identificación del dominio de investigación, luego la selección de estudios a través de bases de datos como IEEE Xplore, ScienceDirect, Scopus y Web of Science, y por último la aplicación de criterios de inclusión y exclusión para filtrar un total de 1,316 artículos, de los cuales solo se seleccionaron 256 para un análisis exhaustivo. Los objetivos principales del estudio se centran en evaluar la representación de lenguaje de señas, la adquisición de datos y la precisión de los métodos de reconocimiento. Así mismo, se concluye que la precisión del reconocimiento puede variar en gran medida, alcanzando de esta manera entre 64\% y 98\% en casos donde se puede conocer la identidad del intérprete, y entre 52\% y 98\% en situaciones donde no es relevante, con un promedio de 87.9\% y 79\% respectivamente.\vspace{0.5cm}\par

Al revisar lo anterior con detenimiento, se pueden identificar desafíos en la caracterización de gestos continuos y de igual manera se destaca la necesidad de mejorar la viabilidad práctica de los sistemas de reconocimiento de gestos basados en visión, así como resaltar la importancia de integrar otros enfoques interdisciplinarios que consideren aspectos de interacción que estén enfocados en la interacción humano-computadora sumada a la complejidad del lenguaje de señas, que al igual que el estudio anterior, se concluye que comprende no solo movimientos de las manos, sino que también expresiones faciales y lenguaje corporal.\vspace{0.5cm}\par

El documento de la investigación menciona varios métodos utilizados en el reconocimiento de gestos, específicamente en el contexto del reconocimiento de lenguaje de señas. Estos métodos se pueden clasificar en tres categorías principales, siendo los primeros los métodos Basados en Visión. Estos métodos se caracterizan por utilizar información visual para reconocer gestos, esto quiere decir que, incluyen varias etapas, como la recopilación de datos, el preprocesamiento, la segmentación, la extracción de características y la clasificación. Estos se enfocan de manera principal en el análisis de imágenes o secuencias de video para identificar gestos estáticos y dinámicos.\vspace{0.5cm}\par

En otra instancia, están los métodos Basados en Sensores, los cuales se enfocan en utilizar sensores, como indica su nombre, que usualmente están integrados en guantes o dispositivos portátiles, que son utilizados para capturar datos sobre los movimientos de las manos. Estos sensores son capaces de medir parámetros como lo son la flexión, la orientación y la rotación de la mano. Esto hace que este método sea menos susceptible a las condiciones que se relacionan al entorno, lo que permite una captura de datos más precisa, aunque puede ser percibido como incómodo debido a la necesidad de usar múltiples dispositivos.\vspace{0.5cm}\par

Por último, se tiene a los métodos Híbridos, estos métodos se caracterizan por combinar técnicas de visión además de sensores para aprovechar las ventajas de ambos enfoques. Al integrar datos visuales y de sensores, se busca mejorar la precisión y la robustez del reconocimiento de gestos. Es importante recalcar que el documento también destaca la importancia de emplear algoritmos de aprendizaje profundo, como lo pueden ser las redes neuronales convolucionales (CNN), para mejorar la eficacia del reconocimiento de gestos, así como la necesidad de abordar aspectos no manuales del lenguaje de señas, como las expresiones faciales y el lenguaje corporal, lo cual puede significar en la omisión de datos que son cruciales para una interpretación fiel del significado en el lenguaje de señas.\vspace{0.5cm}\par

Siguiendo con la idea del uso de sensores, se analiza el estudio \enquote{American Sign Language Recognition and Translation Using Perception Neuron Wearable Inertial Motion Capture System}\autocite[p.~1-15]{Gu2024} el cual trata del reconocimiento y la traducción de la Lengua de Señas Americana (ASL) a través de un sistema de captura de movimiento inercial conocido como \enquote{Perception Neuron}.\vspace{0.5cm}\par

A lo largo del estudio se recopila un conjunto de datos en los cuales se incluyen 300 oraciones comúnmente usadas en ASL, compuestas por 455 gestos diferentes, a los que se les asignan dos tipos de etiquetas. La primera de ellas se basa en la gramática de la lengua de señas, mientras que la otra se asigna desacuerdo a la gramática del lenguaje hablado. Así mismo, se desarrollan dos modelos de procesamiento de lenguaje natural (NLP) para el reconocimiento de secuencias y la traducción de extremo a extremo.\vspace{0.5cm}\par

La metodología de los procesos antes descritos van desde la segmentación manual de palabras para su validación, es decir, se seleccionan 20 palabras para evaluar la precisión del clasificador, que combina un extractor de características CNN y una capa de clasificación totalmente conectada, donde los resultados muestran una alta precisión en la clasificación con un promedio de alrededor del 88\%.\vspace{0.5cm}\par

A pesar de que se identifican confusiones entre palabras con gestos similares, las conclusiones del estudio muestran que, aunque el modelo de reconocimiento logra una alta precisión, se encontró que la traducción de extremo a extremo presenta una mayor cantidad de errores debido a la falta de un conocimiento gramatical. Aparte de eso, se observa que la validación a nivel de oración se vuelve más difícil con un vocabulario más extenso, lo que termina reduciendo la tasa de precisión. Dentro del estudio se subraya de gran manera la importancia de las diferencias individuales dentro de cada uno de los gestos y la necesidad de mejorar la comprensión gramatical para optimizar la traducción de ASL.\vspace{0.5cm}\par

Para tener un enfoque diverso en la metodología para hallar una solución, se revisa el estudio \enquote{Sign language recognition using the fusion of image and hand landmarks through multi-headed convolutional neural network}\autocite[p.~1-11]{Pathan2023} el cual se centra en la fusión de técnicas de procesamiento de imágenes y aprendizaje profundo, más específicamente a través de la utilización de una red neuronal convolucional multi-cabeza (CNN). Para lograrlo se hace uso de un conjunto de datos de imágenes denominado \enquote{Finger Spelling, A} para entrenar el modelo, esto con el objetivo de mejorar la precisión en la detección de gestos de la lengua de señas americana (ASL).\vspace{0.5cm}\par

Las metodologías incluyen la extracción de características utilizando transformadas de características invariantes a escala como lo es (SIFT) y la clasificación mediante el uso de redes neuronales, así también como la implementación de técnicas de detección de bordes como lo pueden ser Canny y ORB. Así mismo, como se ve en otros estudios, se aplican redes neuronales convolucionales 3D (3DRCNN) para capturar tanto la información espacial como temporal de los gestos.\vspace{0.5cm}\par

Para finalizar, este estudio concluye en que la combinación del procesamiento de imágenes tradicional sumado con la extracción de puntos de referencia de la mano más el uso de CNN multi-cabeza puede permitir una tasa de detección mucho mejor, logrando unos resultados positivos incluso en condiciones donde hay mucho ruido y variabilidad en las imágenes. A través de este enfoque no solo se mejora la precisión del reconocimiento, sino que también reduce la necesidad de hardware costoso, lo que lo hace accesible.\vspace{0.5cm}\par

Para analizar en mejor medida como se pueden usar tanto videos como imágenes, se introduce \enquote{Sign Language Recognition System for Communicating to People with Disabilities}\autocite[p.~13-20]{Obi2023} Este estudio se caracteriza por usar una metodología que se basa en redes neuronales convolucionales (CNN) que para poder facilitar la comunicación entre personas con discapacidades auditivas y la sociedad en general, realiza una recolección de un conjunto de datos de señas en lenguaje americano (ASL) de Kaggle, que incluye 24 clases de gestos, aplicando un filtro de desenfoque gaussiano para mejorar la calidad de las imágenes.\vspace{0.5cm}\par

Posteriormente, para poder lograr el objetivo, se implementan diversas técnicas de procesamiento de imágenes, como lo es la detección de contornos, la extracción de características KAZE y la conversión de espacios de color, para poder preparar los datos para su respectiva clasificación. Esta clasificación se realiza utilizando algoritmos como el de vecinos más cercanos y, principalmente, el de CNN, que ha demostrado ser el método más preciso, siendo capas de alcanzar una precisión del 100\% en imágenes y del 73\% en videos.\vspace{0.5cm}\par

En conclusión, lo valioso de este sistema es que está diseñado para recibir entradas de video en tiempo real, procesar las imágenes y convertir los gestos en texto que puede leer cualquier persona, lo cual permite una interacción más fluida y efectiva. También se destaca la importancia de este tipo de tecnologías en la mejora de la comunicación para aquellas personas con discapacidad, subrayando la necesidad de herramientas accesibles y precisas que faciliten la interacción en situaciones cotidianas y críticas.\vspace{0.5cm}\par

Para profundizar aún más sobre los videos y su relación con los autoencoders, se trae a colación el documento \enquote{VTAN: A Novel Video Transformer Attention-Based Network for Dynamic Sign Language Recognition}\autocite[p.~2793-2812]{Deng2024} el cual se caracteriza por utilizar un modelo innovador para el reconocimiento de lenguaje de señas de una manera dinámica, el modelo combina un autoencoder convolucional (CAE) y un transformador que se enfoca en atención suave.\vspace{0.5cm}\par

Ahora bien, en este documento se abordan dos problemas muy importantes, siendo el primero la redundancia de fotogramas importantes en videos de lenguaje de señas y el segundo, la necesidad de enfocarse principalmente en las regiones de las manos, las cuales se considera que son muy importantes para la traducción de gestos. Para lograrlo se usa un módulo de agregación de características visuales, a través de un CAE para extraer fotogramas clave mediante clustering K-means, reduciendo de esta manera los datos redundantes y mejorando de manera considerable la eficiencia computacional. Por otro lado, este mismo módulo de mejora de características espacio-temporales (STHE) emplea un transformador para poder priorizar las características de las manos, capturando de esta manera dinámicas existentes entre el espacio y su temporalidad.\vspace{0.5cm}\par

Para probar lo anterior, los experimentos se realizaron en los conjuntos de datos AUTSL y SLR500, los cuales muestran mejoras significativas en precisión, alcanzando la cifra de 93.6\% y 91.3\%, respectivamente, destacando la efectividad que tiene VTAN frente a otros métodos previos.\vspace{0.5cm}\par

Por último, para finalizar esta breve compilación de los documentos que principalmente moldearon la idea principal, se tiene el trabajo \enquote{G2P-DDM: Generating Sign Pose Sequence from Gloss Sequence with Discrete Diffusion Model}\autocite[p.~6234-6242]{Xie2024} el cual propone un modelo innovador, este modelo se enfoca en la producción de lenguaje de señas (SLP), centrándose en la transformación de secuencias de etiquetas, es decir anotaciones o etiquetas textuales de los signos, en secuencias de poses (G2P) En pocas palabras, una traducción de texto a señas.\vspace{0.5cm}\par

Para poder lograrlo, el estudio utiliza un enfoque que consta de dos etapas, la primera de estas se basa en que el modelo llamado \enquote{Pose-VQVAE} convierte secuencias continuas de poses en códigos latentes discretos, el modelo realiza esta tarea dividiendo el esqueleto humano en tres partes principales siendo estas el cuerpo, la mano derecha y la mano izquierda, empleando múltiples estructuras en códigos para mejorar la reconstrucción. Mientras que en la segunda etapa, la cual se llama \enquote{G2P-DDM}, se basa principalmente en un modelo de difusión discreta, es decir, el modelo genera secuencias de poses a partir de las diferentes etiquetas usando la herramienta CodeUnet. Posteriormente, se utiliza un algoritmo de clustering secuencial-KNN el cual se encarga de predecir longitudes variables en las secuencias.\vspace{0.5cm}\par

En otras palabras, este trabajo centra su investigación en la producción automática de lenguaje de señas al discretizar el espacio de poses y emplear modelos de difusión, para luego abordar desafíos como lo pueden ser la variabilidad en la longitud de las secuencias y la complejidad de los gestos dinámicos. A través del uso de representaciones latentes discretas, las cuales permiten explorar el espacio latente para tareas como la generación de datos sintéticos hasta la interpolación de gestos.

\section*{Identificación de los conceptos principales del problema}

Teniendo en cuenta los estudios previos que se seleccionaron previamente, se realiza un recuento secuencial de como cada uno influencio y moldeo el planteamiento del problema. Bajo ese orden de ideas, se comienza con la necesidad de realizar un avance en un campo, de preferencia uno aún no investigado en gran medida, para poder contribuir en el mismo realizando una investigación que sirva de base.\vspace{0.5cm}\par

El primer estudio \enquote{A Survey on Chinese Sign Language Recognition: From Traditional Methods to Artificial Intelligence}\autocite[p.~1-40]{Jiang2024}, el cual mostró una revisión exhaustiva durante dos décadas de la evolución en el reconocimiento de la Lengua de Señas China (CSL), con la cual se destacó la transición de métodos tradicionales, hacia enfoques más recientes basados en Redes Neuronales Profundas (DNN). Con este enfoque se llegó a una conclusión muy importante, la cual fue resaltar la importancia en capturar la información completa del intérprete, es decir, gestos manuales, expresiones faciales y movimientos corporales, en lugar de limitarse solamente a las manos. Además de mostrar los beneficios de centrarse en la búsqueda de una solución  avanzada, alejándose de enfoques tradicionales y justificando la evolución hacia técnicas de aprendizaje profundo. Por estos motivos se comenzó a indagar en la posibilidad de emplear un autoencoder capaz de procesar toda la información que se le es transmitida, asegurando de esta manera una representación más completa de los datos.\vspace{0.5cm}\par

Por otro lado, el segundo documento, \enquote{A Systematic Review of Hand Gesture Recognition: An Update From 2018 to 2024}\autocite[p.~1-35]{Hashi2024}, fundamento el uso de la herramienta que se planteó en el anterior documento al revisar 1,300 estudios, de los cuales la mayoría perteneció a métodos de visión, sensores e híbridos. Esto quiere decir que los autoencoders no han sido explorados de manera sustancial en comparación con otras técnicas. Esta investigación también llegó a la conclusión que es importante considerar elementos aparte de las manos para el reconocimiento del lenguaje de señas, como las expresiones faciales y otro lenguaje corporal, para llegar a una interpretación precisa. Por lo tanto, lo encontrado solo reforzó aún más la elección de un autoencoder que capture el contexto completo.\vspace{0.5cm}\par

Por el contrario, el tercer estudio, \enquote{American Sign Language Recognition and Translation Using Perception Neuron Wearable Inertial Motion Capture System}\autocite[p.~1-15]{Gu2024}, ayudo a delimitar la idea, pues con su investigación, respecto a la evaluación del uso de sensores inerciales para el reconocimiento de la Lengua de Señas Americana (ASL), expuso las limitaciones de los métodos basados en sensores. Siendo estas su gran costo, la complejidad de implementación y la incomodidad de los usuarios al llevar puestos diferentes dispositivos portátiles. Con lo anterior claro, se pudo descartar esta aproximación para poder llegar a soluciones más accesibles y escalables. Sin embargo, el estudio también resaltó la importancia de distinguir gestos similares, lo que inspiró la idea teórica de utilizar un espacio latente para diferenciarlos según sus distancias representacionales. Además, esta idea es muy compatible con las el funcionamiento de los autoencoders los cuales son capaces de generar representaciones compactas y significativas, sentando las bases para su posible uso no solo en reconocimiento, sino que también en una potencial traducción.\vspace{0.5cm}\par

Teniendo la idea un poco más clara, se pudo explorar una alternativa para poder hacer funcionar lo anterior, así es como en el cuarto estudio, \enquote{Sign language recognition using the fusion of image and hand landmarks through multi-headed convolutional neural network}\autocite[p.~1-11]{Pathan2023}, se demostró el potencial del uso de técnicas que involucran redes 3D convolucionales (3DRCNN) para capturar información espacial y temporal, lo cual sugirió la posibilidad de desarrollar arquitecturas que sean capaces de detectar la temporalidad de los gestos, lo cual es un aspecto muy importante del lenguaje de señas.\vspace{0.5cm}\par

Ahora bien, para sustentar la utilización de los datos, el quinto estudio, \enquote{Sign Language Recognition System for Communicating to People with Disabilities}\autocite[p.~13-20]{Obi2023}, presento una gran idea en el uso de CNN para procesar secuencias de video de ASL, lo cual se puede unir con el anterior estudio demostrando que es posible realizar este proceso, en este caso particular se logró realizar con técnicas de preprocesamiento como detección de contornos y extracción de características. Este documento, además de aportar un ejemplo concreto de éxito en el procesamiento de video, reforzando la confianza en las capacidades de los autoencoders para este propósito, también revelo pasos importantes dentro del preprocesamiento de los videos para tener un mayor margen de éxito.\vspace{0.5cm}\par

De igual manera, para sentar las últimas bases de las generalidades del problema, se revisó el sexto estudio, \enquote{VTAN: A Novel Video Transformer Attention-Based Network for Dynamic Sign Language Recognition}\autocite[p.~2793-2812]{Deng2024}, que introdujo un modelo que ya se centraba completamente en un autoencoder convolucional (CAE) con un transformador, lo cual deja en evidencia su posible potencial que se estableció teóricamente con los primeros estudios analizados. Además, este enfoque abordó un problema clave cuando se trata con videos, siendo este mismo, la redundancia de frames en videos de lenguaje de señas para seleccionar características relevantes y reducir datos innecesarios.\vspace{0.5cm}\par

En última instancia, el séptimo documento, \enquote{G2P-DDM: Generating Sign Pose Sequence from Gloss Sequence with Discrete Diffusion Model}\autocite[p.~6234-6242]{Xie2024}, aunque tiene una aproximación muy diferente, sirvió de inspiración para constatar el cómo sería evaluado el proyecto, al proporcionar un punto teórico que refuerza lo visto en previos estudios y es la implementación e importancia de representaciones latentes discretas dentro de un espacio para realizar traducciones. Esta idea fue clave para definir el enfoque final, pues sirve como puente para sustentar el concepto de utilizar autoencoders no solo para identificar patrones, sino también para traducir palabras en lenguajes de señas a través de un espacio latente. Esta traducción se basa en el comportamiento de diferentes lenguajes de señas en un mismo espacio latente donde se teoriza que luego de un proceso determinado, es posible que se agrupen las mismas palabras de distintos lenguajes, indicando que existe alguna relación que pueda permitir la asociación de etiquetas al ingresar una nueva palabra de un lenguaje que no ha sido entrenado, esto al ubicarse cerca de sus palabras equivalentes en otros idiomas.

\section*{Delimitación del problema}

Dejando en claro como surge la base del problema a través de ciertos documentos claves, ahora se realiza una acotación para poder enfocar el proyecto de investigación a alcances realistas y obtener resultados determinados, para hacer recomendaciones certeras sobre el cómo se puede enfocar una investigación de este tipo en un campo en concreto. Es por esto que se opta por hacer la mención de \enquote{recursos determinados} como una delimitación en la investigación, esto con el fin de responder a una decisión consciente del alcance del proyecto, basada en las herramientas y capacidades accesibles en el contexto de un estudiante de pregrado de la Universidad Sergio Arboleda, sin incurrir en costos monetarios significativos.\vspace{0.5cm}\par

Teniendo lo anterior en cuenta primero se realiza una búsqueda preliminar de los datos a utilizar, esta búsqueda es muy importante, pues desde la teoría y la practica se ha establecido como un principio fundamental que es muy valioso en el aprendizaje automático el señalar que la calidad y el rendimiento de un modelo de IA son directamente proporcionales a la calidad y representatividad de sus datos de entrenamiento, este principio es conocido como \enquote{Garbage In, Garbage Out}\autocite{GIGOEBSCO}.\vspace{0.5cm}\par

Por eso, se establecen los siguientes parámetros de búsqueda basándose en los estudios previamente mencionados, comenzando por la característica que el dataset este compuesto por videos de intérpretes realizando palabras continuas, no por deletreo de señas. Se toma esta decisión para poder detectar la temporalidad de la secuencia que compone a una palabra, como se indica en el estudio \enquote{VTAN: A Novel Video Transformer Attention-Based Network for Dynamic Sign Language Recognition}\autocite[p.~2793-2812]{Deng2024} Además, este parámetro se respalda con los estudios anteriores que denotan la importancia de buscar toda la información que se omite cuando solo se concentra en una seña en particular, al solo tener un deletreo no se hace uso de otras partes del cuerpo que pueden dar información importante adicional.\vspace{0.5cm}\par

Consecuentemente con lo anterior, se busca que los videos contengan vistas completas del cuerpo para capturar toda la información posible, de igual manera que haya cierta diversidad de intérpretes y de videos por palabra es importante, como se menciona en \enquote{A Systematic Review of Hand Gesture Recognition: An Update From 2018 to 2024}\autocite[p.~1-35]{Hashi2024} \enquote{A critical need emerges for the development of more comprehensive and diverse databases to facilitate a more thorough investigation of SLR systems} donde luego se justifica que al cumplir esta diversidad se lograría que el modelo generalizara de mejor manera.\vspace{0.5cm}\par

Siguiendo con los requerimientos, unos muy importantes son los que están relacionados con su calidad, es decir, fondo limpio, condiciones buenas de iluminación, anotaciones y etiquetas consistentes y tamaños normalizados. Esto es muy importante para simplificar pasos de preprocesamiento y limpieza de datos como los que se mencionan en la sección de preprocesamiento de imágenes en el estudio \enquote{A Systematic Review of Hand Gesture Recognition: An Update From 2018 to 2024}\autocite[p.~1-35]{Hashi2024} donde se repasa desde métodos para la Eliminación de objetos no deseados en el fondo hasta la configuración del tamaño de los videos.\vspace{0.5cm}\par

Por último, para lograr una traducción parcial consistente de palabras por medio de sus representaciones latentes se necesita que se tengan las mismas etiquetas, esto implica que cuando se menciona anteriormente la necesidad de tener variedad en las palabras, es importante que se logre sin caer en regionalismos para tener una buena equivalencia entre diferentes idiomas. Consecuentemente, se necesita tener las mismas palabras en diferentes idiomas para lograr dicha equivalencia.\vspace{0.5cm}\par

Después de una búsqueda exhaustiva tanto en los documentos como en la red, se llegó a la conclusión que cuando se delimita la búsqueda según los anteriores parámetros establecidos existe la escasez de datasets públicos, a gran escala y de alta calidad. Los recursos que existen actualmente tiene la particularidad de no cumplir frecuentemente con las características necesarias para un entrenamiento ideal, lo cual no resulta ser una sorpresa, pues ya se han mencionado en este documento, con varios estudios, que a partir de este problema se enfocaron en la creación de datasets de calidad, como lo es el ejemplo de \enquote{A Survey on Chinese Sign Language Recognition: From Traditional Methods to Artificial Intelligence}\autocite[p.~1-40]{Jiang2024}, \enquote{A Systematic Review of Hand Gesture Recognition: An Update From 2018 to 2024}\autocite[p.~1-35]{Hashi2024} y \enquote{VTAN: A Novel Video Transformer Attention-Based Network for Dynamic Sign Language Recognition}\autocite[p.~2793-2812]{Deng2024} el cual se caracteriza por utilizar un modelo innovador para el reconocimiento de lenguaje de señas de una manera dinámica, por mencionar unos pocos.\vspace{0.5cm}\par

A pesar de esto, se pudieron identificar tres datasets que cumplen con la mayoría de lo anteriormente descrito, sin embargo, tienen ciertas limitaciones. El primer dataset seleccionado consiste en videos de palabras del lenguaje de señas americano, este dataset cuenta con alrededor de 2000 palabras, siendo el dataset más grande que hay hasta la fecha de su creación del lenguaje americano, la versión que se emplea del dataset es la 03\autocite{WLASL2020}.\vspace{0.5cm}\par

El segundo dataset que se eligió fue de lenguaje de señas en indio, se escogió este porque aparte de cumplir con la mayoría de requisitos antes descritos, tiene 4292 videos de diferentes palabras, siendo estás muy variadas\autocite{Sridhar2020}.\vspace{0.5cm}\par

El último dataset que se decidió utilizar consiste en 20400 videos grabados por 194 diferentes intérpretes, el problema principal con este dataset es que no están grabados en espacios uniformes y su captura fue con diferentes cámaras\autocite{Kapitanov2023}.\vspace{0.5cm}\par

Se decidió utilizar solo estos tres datasets, pues son los que más videos etiquetados contienen, además de estar abiertos al público general, permitiendo una descarga accesible. También son los que presentan la mayor calidad en la presentación de sus datos, haciéndolos la mejor opción. Sin embargo, las etiquetas y la manera de como los datos están estructurados son totalmente diferentes entre sí, lo que complica el preprocesamiento y unificación de un formato de los datos, por las razones anteriores, se decidió no incluir más datasets, los diferentes costos que representan en tiempo de investigación el incluir más conjuntos de datos que no están estructurados de la misma manera, no es viable. Además, el experimento funciona teóricamente de buena manera con solo dos lenguajes de señas.\vspace{0.5cm}\par

Los recursos que se utilizaron para este proyecto de investigación fueron brindados por la Universidad gracias a las cuentas de prueba académicas de AWS academy learner lab, se contaron con 50 dólares con los cuales se pudo acceder a diferentes cuadernos del servicio Amazon SageMaker AI, que sé alojaron en la nube para ejecutar todo el código. Las mejores instancias a las que se pudieron acceder son las ml.c5.xlarge, estas cuentan con optimización para computación, no son de inicio rapido, 4 vCPU y 8GiB de memoria. No se contó con memoria GPU para la realización del proyecto, por lo cual no se pudo realizar diferentes estrategias de cómputo con CUDA o aceleración con gráficas\autocite{AWSSageMaker2022}. Es importante recalcar que cada sesión del laboratorio tiene un máximo de 4 horas para trabajar antes de que se reinicie, una vez ocurre esto toca volver a cargar todos los recursos, pues se borra toda la información que tenía el kernel, además de tener que encender todos los servicios que se estaban utilizando antes del apagado.\vspace{0.5cm}\par

La última delimitación que se realiza antes de tener el problema completamente formulado es la teórica, se toma la decisión de enfocar el trabajo de investigación en una técnica de aprendizaje autosupervisado (Self-Supervised Learning) para aprender representaciones de video. Se piensa abordar esta estrategia con un modelo que se compone de un autoencoder basado en convoluciones 3D (3D-CNN) para extraer características espaciotemporales, y una Red Neuronal Recurrente (GRU) Bidireccional para modelar las secuencias temporales. Posteriormente, para estructurar el espacio latente se hace uso de una función de pérdida compuesta que incluye la reconstrucción (MSE), múltiples pérdidas triplet para la estructura temporal y una pérdida KL. Por último, se ve el resultado de la estructuración de las representaciones por medio de PCA y UMAP.\vspace{0.5cm}\par

La decisión de utilizar un enfoque de aprendizaje autosupervisado nace del estudio \enquote{Advancing video self-supervised learning via image foundation models}\autocite{Wu2025} el cual señala que hay una manera de realizar de manera eficiente el aprendizaje de un modelo cuando no se dispone de datos etiquetados a nivel de frame. Además, presenta un concepto que se utilizara en el proyecto de investigación, las tareas de pretexto, según la anterior investigación, estas son las que se centran en crear desafíos que permitan a los modelos aprender relaciones espaciales y temporales en los datos sin etiquetas.\vspace{0.5cm}\par

Así mismo la arquitectura 3d se justifica al leer el documento \enquote{Batch feature standardization network with triplet loss for weakly-supervised video anomaly detection}\autocite{Yi2022} en el cual se expone en la sección 2.1 la idea de que los autoencoders, especialmente los 3D, son muy buenos cuando se emplean para aprender representaciones en videos, siendo capaces de reconstruir, con un buen rendimiento, eventos normales y potencialmente anomalías debido a su capacidad de generalización en los patrones espacio-temporales que capturan.\vspace{0.5cm}\par

En acompañamiento a esta arquitectura se establece que la mejor opción sería incluir una capa GRU Bidireccional, esto gracias a las afirmaciones de la investigación \enquote{Entwicklung und Evaluation eines Deep-Learning Algorithmus für die Worterkennung aus Lippenbewegungen für die deutsche Sprache}\autocite{Pham2022} en la cual se establece que, una Red Neuronal Recurrente (GRU) Bidireccional para modelar las secuencias temporales, es una arquitectura más que adecuada para tareas de reconocimiento de acciones y lenguaje de señas en formato de video. Esto lo explica con diferentes aproximaciones, mencionando que las CNN 3D extraen información espacial y temporal de los videos, mientras que las GRU modelan las secuencias temporales, haciéndolo un modelo hibrido que es capas de captar tanto información espacial como temporal en videos.\vspace{0.5cm}\par

En cuanto a las funciones de perdida, se escoge la aproximación antes descrita en el primer párrafo, basándose en el documento \enquote{ATCM-Net: A deep learning method for phase unwrapping based on perception optimization and learning enhancement}\autocite{Xu2025} en donde se describe la formulación de una función de pérdida compuesta y cómo esta combina diferentes componentes para mejorar el entrenamiento y la capacidad del modelo. Al realizar una buena combinación se permite enfocar el aprendizaje en múltiples objetivos, siguiendo prácticas recomendadas para mejorar la precisión y la robustez del modelo. Sin embargo, el método que se expone es uno limitado, es por eso que se decidió adoptar el concepto de la función compuesta, pero empleando triplet loss, se tomó esta decisión luego de analizar el documento \enquote{A novel triplet loss architecture with visual explanation for detecting the unwanted rotation of bolts in safety-critical environments}\autocite{Bolton2025} Donde se expone que el triplet loss está diseñado para ser robusto frente a variaciones en las condiciones de captura. Esto es muy bueno porque permite que el modelo se vuelva invariante a ciertos tipos de ruido, lo que es crítico en el contexto del proyecto de investigación donde, como se explicó anteriormente, los datasets no son los mejores y las imágenes pueden no ser perfectas.\vspace{0.5cm}\par

De igual manera, para poder garantizar que el modelo pueda tener una sólida representación óptima de un dato, se integra el uso combinado de la pérdida de Divergencia de Kullback-Leibler (KL) y el Error Cuadrático Medio (MSE) respaldándose en el documento \enquote{TB-Net: Intra- and inter-video correlation learning for continuous sign language recognition}\autocite{Liu2024} el cual muestra que reconocen la relevancia del principio del IB para el aprendizaje de representaciones. Para ahondar más en este concepto y como afecta al aprendizaje se refirió a la bibliografía de este documento para encontrar que en \enquote{PAC-BAYES INFORMATION BOTTLENECK}\autocite{Wang2022} se evalúa la diferencia entre la distribución de las representaciones latentes aprendidas y una distribución previa simple, por medio de la pérdida de divergencia KL y MSE. Donde se busca minimizar esta divergencia para que de esta forma el espacio latente sea estructurado y evitar que el modelo memorice los datos, lo que se alinea con el objetivo de mantener una representación de mínima complejidad.\vspace{0.5cm}\par

Por último, se decide emplear las herramientas UMAP y TSNE para la visualización de los espacios latentes, donde luego de consultar \enquote{Comparison of dimensionality reduction techniques for the visualisation of chemical space in organometallic catalysis}\autocite{Villares2024} se puede definir que para tener un panorama más completo de los datos, se usarán las dos herramientas donde TSNE puede ser utilizada para obtener una representación inicial de los datos, mientras que UMAP puede afinar esa representación, proporcionando una mejor separación y visualización.

\section*{Definición final del problema}

Luego de la revisión documental completa, que se plantea anteriormente como registro de los antecedentes de la creación y diseño de la solución al problema de investigación, finalmente se llega a su definición completa que se usara para el resto del proyecto de investigación, la cual considerando todo lo anteriormente dicho, contempla que este proyecto de investigación se enfoca en sentar las bases para un contexto debidamente limitado, el análisis de la representación de palabras individuales en un espacio latente a través de unas técnicas y arquitecturas específicas. Donde, principalmente, se busca aportar conocimiento sobre el uso de autoencoders con estrategias específicas para subsanar el problema que se encontró previamente dentro del campo del lenguaje de señas. En otras palabras, el problema de investigación se centra en el comportamiento y la organización de las palabras dentro de un determinado espacio vectorial de baja dimensionalidad, para facilitar su visualización, con el fin de plantear recomendaciones a trabajos futuros que puedan resultar en una posible herramienta que sea capas de unificar el lenguaje de señas. Teniendo en cuenta esto, surge la siguiente pregunta de investigación \enquote{¿En qué medida puede un autoencoder a través de determinadas técnicas, entrenado con tres lenguajes de señas y evaluado con recursos determinados, identificar patrones útiles para representar palabras en un espacio latente?}.